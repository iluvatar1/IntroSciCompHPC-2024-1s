{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors in numerical computation: Floating point numbers\n",
    "\n",
    "- Numbers are represented in bits https://en.wikipedia.org/wiki/Byte?useskin=vector\n",
    "- There is not way to assign infinite bits for infinite precission. A finite number of bits is assigned, some of them spent on the exponent, others on the mantissa, and one on the sign. https://en.wikipedia.org/wiki/Floating-point_arithmetic?useskin=vector\n",
    "- This means a limit in precission, range, and even density (https://docs.python.org/3/tutorial/floatingpoint.html). There are 8388607 single precision numbers between 1.0 and 2.0, but only 8191 between 1023.0 and 1024.0\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/FloatingPointPrecisionAugmented.png/1000px-FloatingPointPrecisionAugmented.png\" alt=\"Image Description\" width=\"900\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/FloatingPointPrecisionAugmented.png/1000px-FloatingPointPrecisionAugmented.png\"</figcaption>\n",
    "</div>\n",
    "   \n",
    "\n",
    "- To avoid differences across platforms, the IEE754 standard stablished rules for approximation, truncation, and so on. https://en.wikipedia.org/wiki/IEEE_754?useskin=vector . Languages like c/c++/fortran/python support the standard. In particular, for scientific applications try to use 'double' precission\n",
    "\n",
    "- There are several possible representation of floating point numbers, like Fixed point (https://en.wikipedia.org/wiki/Fixed-point_arithmetic), decimal representation, etc, but the common one in the IEEE754 standard is an \"exponential\" scientific notation. Play with https://bartaz.github.io/ieee754-visualization/\n",
    "\n",
    "\n",
    "    | Format   | bits | exponent bits | Significand bits | Machine eps  |\n",
    "    |----------|----------|----------|----------|----------|\n",
    "    |   float   |  32   |  8  |   23   |   $10^{-7}$  |\n",
    "    |   double  |  64   |  11   |   52   |   $10^{-16}$   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./over-under-truncation.png\" alt=\"under-over-truncation\" class=\"centerimg50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- For more fp representation details, check\n",
    "  - https://bartaz.github.io/ieee754-visualization/\n",
    "  - https://float.exposed/0x44c00000\n",
    "  - https://www.h-schmidt.net/FloatConverter/IEEE754.html\n",
    "  - https://en.wikipedia.org/wiki/Floating-point_arithmetic\n",
    "  - https://trekhleb.dev/blog/2021/binary-floating-point/\n",
    "\n",
    "Some warnings:\n",
    "- 14 decimal places can be lost in a single operation.\n",
    "- Do not cast floats to integers and viceversa\n",
    "- Addition is no longer associative: $x + (y+z) != (x+y) + z $. Use $x = -1.5e38, y = -1.5e38, z = 1$. \n",
    "- Not every number can be exactly represented (1/3, 0.1, etc)\n",
    "- Compilers has many flags, explore them (-ffast-math, -ffloat-store).\n",
    "\n",
    "For some dramatic examples of FP errors, check:\n",
    "- https://www.iro.umontreal.ca/~mignotte/IFT2425/Disasters.html\n",
    "- https://web.ma.utexas.edu/users/arbogast/misc/disasters.html\n",
    "- https://slate.com/technology/2019/10/round-floor-software-errors-stock-market-battlefield.html\n",
    "- https://stackoverflow.com/questions/2732845/real-life-example-fo-floating-point-error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Overflow for integers\n",
    "\n",
    "We will add 1 until some error occurs\n",
    "\n",
    "```cpp\n",
    "#include <cstdio>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int a = 1;\n",
    "  while(a > 0) {\n",
    "    a *= 2 ;\n",
    "    std::printf(\"%10d\\n\", a);\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Underflow and overflow for floats\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <cstdlib>\n",
    "\n",
    "typedef float REAL;\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  std::cout.precision(16);\n",
    "  std::cout.setf(std::ios::scientific);\n",
    "  int N = std::atoi(argv[1]);\n",
    "  REAL under = 1.0, over = 1.0;\n",
    "  for (int ii = 0; ii < N; ++ii){\n",
    "    under /= 2.0;\n",
    "    over *= 2.0;\n",
    "    std::cout << ii << \"\\t\"\n",
    "              << under << \"\\t\"\n",
    "              << over << \"\\n\";\n",
    "  }\n",
    "\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Test for associativity\n",
    "\n",
    "```cpp\n",
    "#include <cstdio>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  float x = -1.5e38, y = 1.5e38, z = 1;\n",
    "  printf(\"%16.6f\\t%16.6f\\n\", x + (y+z), (x+y) + z);\n",
    "  printf(\"%16.16f\\n\", 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1);\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Machine eps\n",
    "\n",
    "You can also compute/verify the machine precision $\\epsilon_m$ of your machine according to different types. The machine precision is a number that basically rounds to zero and in opertation. It can be represented as $1_c + \\epsilon_m = 1_c$, where $1_c$ is the computational representation of the number 1. Actually, that means than any real number $x$ is actually represented as \n",
    " $$x_c = x(1+\\epsilon), |\\epsilon| \\le \\epsilon_m .$$\n",
    "\n",
    "Implement the following algorithm to compute it and report your results:\n",
    "```sh\n",
    "eps = 1.0\n",
    "begin do N times\n",
    "    eps = eps/2.0\n",
    "    one = 1.0 + eps\n",
    "    print\n",
    "```\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <cstdlib>\n",
    "\n",
    "typedef long double REAL;\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{   \n",
    "  std::cout.precision(20);\n",
    "  std::cout.setf(std::ios::scientific);\n",
    "\n",
    "  int N = std::atoi(argv[1]);\n",
    "  REAL eps = 1.0, one = 0.0;\n",
    "  for (int ii = 0; ii < N; ++ii){\n",
    "    eps /= 2.0;\n",
    "    one = 1.0 + eps;\n",
    "    std::cout << ii << \"\\t\"\n",
    "              << one << \"\\t\"\n",
    "              << eps << \"\\n\";\n",
    "  }\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Practical example: Series expansion of $e^{-x}$\n",
    "The function $e^{-x}$ can be expanded as \n",
    "$$e^{-x} = \\sum_{i=0}^{\\infty} (-1)^i \\frac{x^i}{i!} = 1 -  x + \\frac{x^2}{2} - \\frac{x^3}{6} + \\ldots \\ (|x| < \\infty)$$\n",
    "\n",
    "This is a great expansion, valid for all finite values of $x$. But, **what numerical problems do you see?**\n",
    "\n",
    "Implement a function that receives $x$ and $N$ (max number of terms), and saves the iteration value of the series as a function of $i$ in a file called `sumdata.txt`. Then load the data and plot it. Use $N = 10000$ and $x=1.8766$. You will need to implement also a factorial function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <cmath>\n",
    "\n",
    "int factorial(int n);\n",
    "double fnaive(double x, int N);\n",
    "double fsmart(double x, int N);\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  std::cout.precision(16); std::cout.setf(std::ios::scientific);\n",
    "  double x = 1.234534534;\n",
    "  for (int NMAX = 0; NMAX <= 100; ++NMAX) {\n",
    "    std::cout << NMAX\n",
    "              << \"\\t\" << fnaive(x, NMAX)\n",
    "              << \"\\t\" << std::fabs(fnaive(x, NMAX) - std::exp(-x))/std::exp(-x)\n",
    "              << \"\\t\" << fsmart(x, NMAX)\n",
    "              << \"\\t\" << std::fabs(fsmart(x, NMAX) - std::exp(-x))/std::exp(-x)\n",
    "              << std::endl;\n",
    "  }\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "double fnaive(double x, int N)\n",
    "{\n",
    "  double term = 0, suma = 0;\n",
    "  for(int k = 0; k <= N; ++k){\n",
    "    term = std::pow(-x, k)/factorial(k);\n",
    "    suma += term;\n",
    "  }\n",
    "  return suma;\n",
    "}\n",
    "\n",
    "int factorial(int n)\n",
    "{\n",
    "  if (n <= 0) return 1;\n",
    "  return n*factorial(n-1);\n",
    "}\n",
    "\n",
    "double fsmart(double x, int N)\n",
    "{\n",
    "  double term = 1, suma = 1;\n",
    "  for(int k = 0; k < N; ++k){\n",
    "    term *= (-x)/(k+1);\n",
    "    suma += term;\n",
    "  }\n",
    "  return suma;\n",
    "}\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise: Substractive cancellation with the Quadratic equation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise: Sum ups and down\n",
    "\n",
    "Is there any computation difference between the following sums?\n",
    "\n",
    "\\begin{align}\n",
    "S_{up}(N) &= \\sum_{n=1}^{N} \\frac{1}{n},\\\\\n",
    "S_{down}(N) &= \\sum_{n=N}^{1} \\frac{1}{n}.\n",
    "\\end{align}\n",
    "\n",
    "Implement and plot the relative difference among them as a function of\n",
    "$N$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors\n",
    "- FP is well defined through the IEEE754 standard. \n",
    "- A simple substraction could destroy 15 decimal places of precision\n",
    "- You should not cast floats to integers\n",
    "- You should normalize your models to natural units\n",
    "- Addition is not always associative: $x + (y + z) \\ne (x+y) + z$, when $x = -1.5\\times 10^{38}, y = +1.5\\times 10^{38}, z = 1.0$ (single precision)\n",
    "- All numbers can be represented in binary: false. Check 0.1, or 0.3\n",
    "\n",
    "For some dramatic examples of FP errors, check:\n",
    "- https://www.iro.umontreal.ca/~mignotte/IFT2425/Disasters.html\n",
    "- https://web.ma.utexas.edu/users/arbogast/misc/disasters.html\n",
    "- https://slate.com/technology/2019/10/round-floor-software-errors-stock-market-battlefield.html\n",
    "- https://stackoverflow.com/questions/2732845/real-life-example-fo-floating-point-error\n",
    "\n",
    "Kind of errors\n",
    "- Probability of an error: `start` $\\to U_1 \\to U_2 \\to \\ldots \\to U_n \\to$ `end`\n",
    "- Blunders: Typographical, wrong program, etc\n",
    "- Random errors: Electronics, alien invasion, etc\n",
    "- Approximation: (mathematical series truncation)\n",
    "- Roundoff and truncation of a number in the computer representation\n",
    "\n",
    "### Roundoff/truncation example\n",
    "Let's compute the following sum as a function of $k$, \n",
    "$f(k) = \\left|\\frac{k}{10} - \\sum_{i=1}^k 0.1\\right|$\n",
    "Mathematically, this function should give 0 always. Is that true?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substractive cancellation\n",
    "Given $a = b-c$, then $a_c = b_c-c_c$, therefore\n",
    "\\begin{align}\n",
    "a_c &= a(1+\\epsilon_a ) = b_c - c_c = b(1+\\epsilon_b ) - c(1+\\epsilon_c )\\\\\n",
    "\\frac{a_c}{a} &= 1 + \\epsilon_b \\frac{b}{a} - \\frac{c}{a}\\epsilon_c  \n",
    "\\end{align}\n",
    "so the error in $a$ is about\n",
    "$$\\epsilon_a = \\frac{b}{a}(\\epsilon_b - \\epsilon_c), $$ \n",
    "which is much larger, when $b$ and $c$ are close (so $a$ is small).\n",
    "\n",
    "#### Example of substrative cancellation\n",
    "The following series,\n",
    "$$S_N^{(1)} = \\sum_{n=1}^{2N} (-1)^n \\frac{n}{n+1},$$\n",
    "can be written in two mathematically equivalent ways:\n",
    "$$S_N^{(2)} = -\\sum_{n=1}^{N} \\frac{2n-1}{2n} + \\sum_{n=1}^{N} \\frac{2n}{2n+1},$$\n",
    "and\n",
    "$$S_N^{(3)} = \\sum_{n=1}^{N} \\frac{1}{2n(2n+1)}.$$\n",
    "\n",
    "**Could there be any computational difference? why?**\n",
    "\n",
    "Write a program that compute all sums, and , assuming that $S_n^{(3)}$ is the best option (why?), plots the relative difference with the other sums as a function of $N$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Total errors in algorithms and their computational implementation\n",
    "As you can see, there are several source for errors in computation. Some come from the mathematical approximation, , called $\\epsilon_a$, and some others are intrinsic from the numerical representation, and we can call them $\\epsilon_r$. Sometimes, the rounding/truncation error are modeled as a random walk, $\\epsilon_r \\simeq \\sqrt{N} \\epsilon_m$, where $\\epsilon_m$ is the machine precision, and $N$ is the representative number of \"steps\".  From here, the total error can be estimated as \n",
    "\\begin{align}\n",
    "\\epsilon_{\\rm tot} &= \\epsilon_a + \\epsilon_r \\\\\n",
    "&= \\frac{\\alpha}{N^\\beta} + \\sqrt{N} \\epsilon_m.\n",
    "\\end{align}\n",
    "You can derive this equation an compute the optimal value for $N$, which will depend on the order of the mathematical algorithm and the machine precision. The next table show some examples that illustrate this point:\n",
    "\n",
    "<img src=\"./totalerrors.png\" alt=\"under-over-truncation\" class=\"centerimg80\">\n",
    "\n",
    "## How to minimize numerical errors?\n",
    "\n",
    "-   Use numerical libraries: lapack, eigen, standard c++ lib\n",
    "    (<https://en.cppreference.com/w/>,\n",
    "    <https://hackingcpp.com/cpp/cheat_sheets.html>)\n",
    "-   Analize extreme cases, try to rewrite the expressions:\n",
    "    <http://herbie.uwplse.org/>\n",
    "-   Minimize the use of substractions of similar numbers, operations\n",
    "    between very large and/or very small numbers, normalize your models\n",
    "-   Some interesting refs:\n",
    "    -   <https://phys.org/news/2021-07-rounding-errors-stopwatches-wrong-winners.html>\n",
    "    -   <https://docs.oracle.com/cd/E19957-01/800-7895/800-7895.pdf>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
