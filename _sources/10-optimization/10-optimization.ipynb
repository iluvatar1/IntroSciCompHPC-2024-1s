{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d828fe-2a4b-4e94-b6c3-0ddf9429883b",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "First of all :\n",
    "\n",
    "> \"Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%.\" - Donald Knuth\n",
    "\n",
    "First, make your program correct, then measure, then optimize.\n",
    "Optimization can be achieved by just using compiler flags, by using\n",
    "already optimized libraries, and sometimes by being careful with our\n",
    "memory usage. Some low level techniques are better left to the compiler.\n",
    "\n",
    "Some tips: <https://news.ycombinator.com/item?id=39564632>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929df8c7",
   "metadata": {},
   "source": [
    "\n",
    "## Compiler flags\n",
    "\n",
    "See : <https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html>\n",
    "\n",
    "Some warnings:\n",
    "-   Optimizations enabled by -ffast-math: <https://kristerw.github.io/2021/10/19/fast-math/>\n",
    "-   Beware of fast-math: <https://simonbyrne.github.io/notes/fastmath/>\n",
    "-   Beware of fast-math (Hackernews discussion): <https://news.ycombinator.com/item?id=29201473>\n",
    "\n",
    "Sometimes just using compiler optimization flags with can improve\n",
    "dramatically our code performance. Normally, you want to run your code\n",
    "through several compiler flags to check for speed ups but also for\n",
    "possible uncovered bugs.\n",
    "\n",
    "Compile without (`-O0`) and with optimization (`-O3`) the following code\n",
    "and compare their runtime (this is a very old c-based code but still works):\n",
    "\n",
    "``` c\n",
    "// Credits : Ivan Pulido\n",
    "/* Shows a way to do operations that require a specific order (e.g.,\n",
    " * transpositions) while avoiding cache misses. */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <time.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define min( a, b ) ( ((a) < (b)) ? (a) : (b) )\n",
    "\n",
    "int main(){\n",
    "    const int n = 512;\n",
    "    const int csize = 32;\n",
    "    float ***a, ***b;\n",
    "    clock_t cputime1, cputime2;\n",
    "    int i,j,k,ii,jj,kk;\n",
    "\n",
    "    // Allocating memory for array/matrix\n",
    "    a = malloc(n*sizeof(float **));\n",
    "    for (i=0; i<n; i++){\n",
    "        a[i] = malloc(n*sizeof(float*));\n",
    "        for (j=0; j<n; j++)\n",
    "            a[i][j] = malloc(n*sizeof(float));\n",
    "    }\n",
    "    b = malloc(n*sizeof(float **));\n",
    "    for (i=0; i<n; i++){\n",
    "        b[i] = malloc(n*sizeof(float*));\n",
    "        for (j=0; j<n; j++)\n",
    "            b[i][j] = malloc(n*sizeof(float));\n",
    "    }\n",
    "\n",
    "    // Filling matrices with zeros\n",
    "    for(i=0; i<n; ++i)\n",
    "        for (j=0; j<n; ++j)\n",
    "            for (k=0; k<n; ++k)\n",
    "                a[i][j][k] = 0;\n",
    "    for(i=0; i<n; ++i)\n",
    "        for (j=0; j<n; ++j)\n",
    "            for (k=0; k<n; ++k)\n",
    "                b[i][j][k] = 0;\n",
    "\n",
    "    // Direct (inefficient) transposition\n",
    "    cputime1 = clock();\n",
    "    for (i=0; i<n; ++i)\n",
    "        for (j=0; j<n; ++j)\n",
    "            for (k=0; k<n; ++k)\n",
    "                a[i][j][k] = b[k][j][i];\n",
    "    cputime2 = clock() - cputime1;\n",
    "    printf(\"Time for transposition: %f\\n\", ((double)cputime2)/CLOCKS_PER_SEC);\n",
    "\n",
    "    // Transposition using cache-blocking\n",
    "    cputime1 = clock();\n",
    "    for (ii=0; ii<n; ii+=csize)\n",
    "        for (jj=0; jj<n; jj+=csize)\n",
    "            for (kk=0; kk<n; kk+=csize)\n",
    "                for (i=ii; i<min(n,ii+csize-1); ++i)\n",
    "                    for (j=jj; j<min(n,jj+csize-1); ++j)\n",
    "                        for (k=kk; k<min(n,kk+csize-1); ++k)\n",
    "                            a[i][j][k] = b[k][j][i];\n",
    "    cputime2 = clock() - cputime1;\n",
    "    printf(\"Time for transposition: %f\\n\", ((double)cputime2)/CLOCKS_PER_SEC);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "When you compile without optimization and execute, you will get\n",
    "something like\n",
    "\n",
    "``` shell\n",
    "gcc -O0 cache_blocking.c\n",
    "./a.out\n",
    "```\n",
    "\n",
    "But, if you use optimization, you can get an important improvement\n",
    "\n",
    "``` shell\n",
    "gcc -O2 cache_blocking.c\n",
    "./a.out\n",
    "```\n",
    "\n",
    "Actually we can compare all optimization levels to check their impact:\n",
    "\n",
    "``` shell\n",
    "for level in 0 1 2 3; do echo \"level: $level\"; gcc -O$level cache_blocking.c; ./a.out; done\n",
    "```\n",
    "\n",
    "Be careful when using `-O3`: it activates some unsafe math optimizations\n",
    "that will not respect IEEE754.\n",
    "\n",
    "### Exercise\n",
    "Vary both the matrix size and the cache size to compute both times. Plot the results on two different 3d plots (in gnuplot use `splot`). Repeat for `-O0` and `-O2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8c21e",
   "metadata": {},
   "source": [
    "\n",
    "## Memory layout\n",
    "\n",
    "The memory layout should always be taken into account since cache misses\n",
    "will greatly affect a program performance. Always measure with a\n",
    "profiler and if possible with cachegrind in order to detect possible\n",
    "excessive cache misses.\n",
    "\n",
    "The following code shows how a simple index change in a matrix operation\n",
    "could have a huge impact on the app performance:\n",
    "\n",
    "``` cpp\n",
    "// Credit Ivan Pulido\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "\n",
    "int main(){\n",
    "    const int n = 256;\n",
    "    clock_t cputime1, cputime2;\n",
    "    float ***a;\n",
    "    int i,j,k;\n",
    "\n",
    "    // Allocating memory for array/matrix\n",
    "    a = malloc(n*sizeof(float **));\n",
    "    for (i=0; i<n; i++){\n",
    "        a[i] = malloc(n*sizeof(float*));\n",
    "        for (j=0; j<n; j++)\n",
    "            a[i][j] = malloc(n*sizeof(float));\n",
    "    }\n",
    "    cputime1 = clock();\n",
    "    for (k=0; k<n; ++k)\n",
    "        for (j=0; j<n; ++j)\n",
    "            for (i=0; i<n; ++i)\n",
    "                a[i][j][k] = 1.0;\n",
    "    cputime2=clock() - cputime1;\n",
    "    printf(\"Time with fast index inside: %lf\\n\", ((double)cputime2)/CLOCKS_PER_SEC);\n",
    "\n",
    "    cputime1 = clock();\n",
    "    for(i=0; i<n; ++i)\n",
    "        for (j=0; j<n; ++j)\n",
    "            for (k=0; k<n; ++k)\n",
    "                a[i][j][k] = 2.3;\n",
    "    cputime2=clock() - cputime1;\n",
    "    printf(\"Time with fast index outside: %lf\\n\", ((double)cputime2)/CLOCKS_PER_SEC);\n",
    "\n",
    "    // Clearing memory\n",
    "    for (i=0; i<n; i++){\n",
    "        for (j=0; j<n; j++)\n",
    "            free(a[i][j]);\n",
    "        free(a[i]);\n",
    "    }\n",
    "    free(a);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "```shell\n",
    "gcc codes/cache_lines.c\n",
    "./a.out\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a191e2",
   "metadata": {},
   "source": [
    "\n",
    "Being nice to the cache comes from the modern cpu architecture, as shown\n",
    "in the next figure\n",
    "\n",
    "L1, L2 and L3 caches. Source\n",
    "<https://medium.com/software-design/why-software-developers-should-care-about-cpu-caches-8da04355bb8a>\n",
    "\n",
    "<img src=\"./cpu-caches.png\" class=centerimg80>\n",
    "\n",
    "The relative bandwidth across the different cpu and momory controllers\n",
    "explain why it is important to have the processed data as much time as\n",
    "possible in the cache\n",
    "\n",
    "Relative bandwidth across different cpu and computer parts. Credit:\n",
    "<https://cs.brown.edu/courses/csci1310/2020/assign/labs/lab4.html\n",
    "\n",
    "<img src=\"./bandwidth.png\" class=centerimg80>\n",
    "\n",
    "Since c/c++ store matrices in row major order, then accesing the memory\n",
    "in the same way will benefit the cache and therefore increases our\n",
    "program performance.\n",
    "\n",
    "\n",
    "### Exercise\n",
    "- Vary again the matrix size. Is the time difference important for all sizes? plot it.\n",
    "\n",
    "- Explore the effect of different optimization flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9e428",
   "metadata": {},
   "source": [
    "\n",
    "## What data structures to use?\n",
    "\n",
    "It depends greatly from the problem. But for the typical applications of\n",
    "vector and matrix computations, we can expect that homogeneous and\n",
    "contiguous arrays are the data structures to go. In that case, it is\n",
    "advisable to use `std::vector` as the go to data struct since it is as\n",
    "efficient as an primitive arra, handles automatically the dynamic memory\n",
    "in the heap, and plays nice with the C++ STL.\n",
    "\n",
    "A primitive static array is limited by the stack. Play with the values\n",
    "of M and N in the following code until you get a seg fault just by\n",
    "running the code.\n",
    "\n",
    "``` cpp\n",
    "#include <iostream>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    const int M = 7000;\n",
    "    const int N = 500;\n",
    "    double data[M][N] = {{0.0}};\n",
    "\n",
    "    std::cout << data[M/2][N/2] << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "Is the maximum size related somehow with the output of the command\n",
    "`ulimit -s` ?\n",
    "\n",
    "To be able to use more memory, you could better use dynamic memory with\n",
    "primitive arrays, but you will have to manage the `new/delete` parts in\n",
    "your code. Check that foloowing code does not die on the same sizes as\n",
    "the previous one\n",
    "\n",
    "``` cpp\n",
    "#include <iostream>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    const int M = 7000;\n",
    "    const int N = 500;\n",
    "\n",
    "    double **data = nullptr;\n",
    "    data = new double *[M];\n",
    "    for (int ii = 0; ii < M; ++ii){\n",
    "        data[ii] = new double [N];\n",
    "    }\n",
    "\n",
    "    std::cout << data[M/2][N/2] << std::endl;\n",
    "\n",
    "    for (int ii = 0; ii < M; ++ii){\n",
    "        delete [] data[ii];\n",
    "    }\n",
    "    delete [] data;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "But be careful, memory obtained susing double/multiple pointers is not\n",
    "guaranteed to be contigous, so it is much better to just ask for a large\n",
    "one-dimensional array and just model the 2D shape with smart indexes\n",
    "\n",
    "``` cpp\n",
    "#include <iostream>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  const int M = 7000;\n",
    "  const int N = 500;\n",
    "\n",
    "  double *data = nullptr;\n",
    "  data = new double [M*N];\n",
    "\n",
    "  // [id][jd] -> id*N + jd\n",
    "  std::cout << data[M*N/2 + N/2] << std::endl;\n",
    "\n",
    "  delete [] data;\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "This is an example of a 2d array actually stored as a 1d array in memory:\n",
    "<img src=\"fig/2d-array-memory.png\" class=centerimg80>\n",
    "\n",
    "And this is the illustration of the mapping that allows us to go to/from different dimensions:\n",
    "<img src=\"fig/1d-2d-mapping.png\" class=centerimg80>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Finally, to avoid managing manually the memory, it is much better to use\n",
    "`std::vector`,\n",
    "\n",
    "``` cpp\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    const int M = 7000;\n",
    "    const int N = 500;\n",
    "\n",
    "    std::vector<double> data;\n",
    "    data.resize(M*N);\n",
    "\n",
    "    // [id][jd] -> id*N + jd\n",
    "    std::cout << data[M*N/2 + N/2] << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "### Exercise\n",
    "- Test the stack program to find the maximum matrix size you can use\n",
    "- Do the same for the last one using a vector, what is the maximum size you can reserve? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6e64f",
   "metadata": {},
   "source": [
    "\n",
    "## Blocking multiplication\n",
    "\n",
    "See <https://malithjayaweera.com/2020/07/blocked-matrix-multiplication/>\n",
    "\n",
    "Blocking techniques are neat examples that show how being aware of the\n",
    "cache allows you to increase the performance dramatically. For instance,\n",
    "the following code shows a concrete example where a blocking techinque\n",
    "is used to compute the transpose of a matrix, with a important\n",
    "performance advantage:\n",
    "\n",
    "``` c\n",
    "// Credits: Ivan Pulido\n",
    "/* Shows a way to do operations that require a specific order (e.g., \n",
    " * transpositions) while avoiding cache misses. */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <time.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define min( a, b ) ( ((a) < (b)) ? (a) : (b) )\n",
    "\n",
    "int main(){\n",
    "const int n = 512;\n",
    "  const int csize = 32;\n",
    "  float ***a, ***b;\n",
    "  clock_t cputime1, cputime2;\n",
    "  int i,j,k,ii,jj,kk;\n",
    "\n",
    "  // Allocating memory for array/matrix\n",
    "  a = malloc(n*sizeof(float **));\n",
    "  for (i=0; i<n; i++){\n",
    "    a[i] = malloc(n*sizeof(float*));\n",
    "    for (j=0; j<n; j++)\n",
    "      a[i][j] = malloc(n*sizeof(float));\n",
    "  }\n",
    "  b = malloc(n*sizeof(float **));\n",
    "  for (i=0; i<n; i++){\n",
    "    b[i] = malloc(n*sizeof(float*));\n",
    "    for (j=0; j<n; j++)\n",
    "      b[i][j] = malloc(n*sizeof(float));\n",
    "  }\n",
    "\n",
    "  // Filling matrices with zeros\n",
    "  for(i=0; i<n; ++i)\n",
    "    for (j=0; j<n; ++j)\n",
    "      for (k=0; k<n; ++k)\n",
    "        a[i][j][k] = 0;\n",
    "  for(i=0; i<n; ++i)\n",
    "    for (j=0; j<n; ++j)\n",
    "      for (k=0; k<n; ++k)\n",
    "        b[i][j][k] = 0;\n",
    "\n",
    "  // Direct (inefficient) transposition\n",
    "  cputime1 = clock();\n",
    "  for (i=0; i<n; ++i)\n",
    "    for (j=0; j<n; ++j)\n",
    "      for (k=0; k<n; ++k)\n",
    "        a[i][j][k] = b[k][j][i];\n",
    "  cputime2 = clock() - cputime1;\n",
    "  printf(\"Time for transposition: %f\\n\", ((double)cputime2)/CLOCKS_PER_SEC);\n",
    "\n",
    "  // Transposition using cache-blocking\n",
    "  cputime1 = clock();\n",
    "  for (ii=0; ii<n; ii+=csize)\n",
    "    for (jj=0; jj<n; jj+=csize)\n",
    "      for (kk=0; kk<n; kk+=csize)\n",
    "        for (i=ii; i<min(n,ii+csize-1); ++i)\n",
    "          for (j=jj; j<min(n,jj+csize-1); ++j)\n",
    "            for (k=kk; k<min(n,kk+csize-1); ++k)\n",
    "              a[i][j][k] = b[k][j][i];\n",
    "  cputime2 = clock() - cputime1;\n",
    "  printf(\"Time for transposition: %f\\n\", ((double)cputime2)/CLOCKS_PER_SEC);\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Compiling and running give the following results\n",
    "\n",
    "``` shell\n",
    "gcc cache_blocking.c\n",
    "./a.out\n",
    "```\n",
    "\n",
    "The second one shows how being cache friendly really helps the\n",
    "performance.\n",
    "\n",
    "### Exercise\n",
    "- Plot the time with the direct and the blocking approaches as functions of size, using `-O2`. What can you conclude?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c452e",
   "metadata": {},
   "source": [
    "\n",
    "## Using scientific libraries\n",
    "\n",
    "Scientific libraries are written by people with deep knowledge of the\n",
    "computer and algorithms internals , therefore saving developer time and\n",
    "resources. One should always try to use a established scientific library\n",
    "instead of writting everything from scratch. Sometimes even automatic\n",
    "parallelization comes for free. Examples are the Intel or AMD math\n",
    "libraries, the Cuda toolkit for programming on nvidia cards, and so on.\n",
    "\n",
    "The following examples shows the time taken to transpose a matrix using\n",
    "a traditional approach, a blocking approach , and the eigen c++ library.\n",
    "\n",
    "giving the following results:\n",
    "\n",
    "``` bash\n",
    "Time for memory allocation: 0.315618\n",
    "Time for filling: 3.607817\n",
    "Time for direct transposition: 2.870691\n",
    "Time for blocked transposition: 0.380954\n",
    "Time for transposition with eigen: 0.031344\n",
    "Time for transposition with copy in eigen: 0.310033\n",
    "Time for transposition with full copy in eigen: 3.339495\n",
    "-2999.9\n",
    "-2999.9\n",
    "15200.1\n",
    "15200.1\n",
    "15200.1\n",
    "```\n",
    "\n",
    "This shows, for instance, that eigen in some cases is not even computing\n",
    "the transpose but just creating an expression to access the original\n",
    "matrix, hence the huge speeedup and also the slow down when fully\n",
    "creating a copy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57948af",
   "metadata": {},
   "source": [
    "\n",
    "## Other optimization techniques\n",
    "\n",
    "There are other techniques sometimes applied in very speficic\n",
    "situations, like\n",
    "\n",
    "-   Loop interchanges\n",
    "-   Loop unrolling\n",
    "\n",
    "``` cpp\n",
    "for(int ii = 0; ii < n; ii++) {\n",
    "    array[ii] = 2*ii;\n",
    "}\n",
    "```\n",
    "\n",
    "``` cpp\n",
    "for(int ii = 0; ii < n; ii += 3) {\n",
    "    array[ii] = 2*ii;\n",
    "    array[ii+1] = 2*(ii+1);\n",
    "    array[ii+2] = 2*(ii+2);\n",
    "}\n",
    "```\n",
    "\n",
    "-   Loop Fusion/Fision\n",
    "-   Prefetching\n",
    "-   Floating point division\n",
    "-   Vectorization\n",
    "-   etc\n",
    "\n",
    "In general those techniques can applied after a careful determination\n",
    "that they are really needed, and sometimes the compilers already apply\n",
    "them at some optimization levels. Therefore it is advisable to focus on\n",
    "the clarity of the program first and let the compiler do its job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede67739",
   "metadata": {},
   "source": [
    "\n",
    "## Other resources\n",
    "\n",
    "-   <https://www.agner.org/optimize/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d2063",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
