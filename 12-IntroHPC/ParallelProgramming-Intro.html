
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>12. Introduction to High Performance Computing &#8212; Introduction to Scientific and High Performance Computing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/styles.css?v=03b9d5b1" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '12-IntroHPC/ParallelProgramming-Intro';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="13. Introduction to OpenMp (Shared memory)" href="../13-OpenMP/OpenMP-Intro.html" />
    <link rel="prev" title="11. Performance measurement for some matrix ops" href="../11-matrix-performance/11-matrix-performance.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Nanoscience_High-Performance_Computing_Facility.jpg/1600px-Nanoscience_High-Performance_Computing_Facility.jpg" class="logo__image only-light" alt="Introduction to Scientific and High Performance Computing - Home"/>
    <script>document.write(`<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Nanoscience_High-Performance_Computing_Facility.jpg/1600px-Nanoscience_High-Performance_Computing_Facility.jpg" class="logo__image only-dark" alt="Introduction to Scientific and High Performance Computing - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction to Scientific and High Performance Computing
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to scientific computing and programming tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01-Introduction/01-Introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02-errorsfpnumbers/ErrorsFPNumbers.html">2. Errors in Floating Point Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-Makefiles/04-Makefiles.html">3. Makefiles as automation tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06-stdlib-randomnumbers/06-stdlib-randomnumbers.html">4. Standard library of functions: math functions, containers and random numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07-Install-Programs-From-Source/07-Install-Programs-From-Source.html">5. Using software in a hpc environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-Debugging/09-Debugging.html">6. Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-UnitTest/09-UnitTesting.html">7. Unit Testing : Ensuring fix and correct behavior last</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">High Performance Computing and Parallel Programming</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../10-optimization/10-optimization.html">8. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-profiling/10-profiling.html">9. Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11-matrices-numericallibs/11-matrices-numericallibs.html">10. Numerical libraries in Matrix Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11-matrix-performance/11-matrix-performance.html">11. Performance measurement for some matrix ops</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">12. Introduction to High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13-OpenMP/OpenMP-Intro.html">13. Introduction to OpenMp (Shared memory)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../14-MPI/MPI-Intro.html">14. Introduction to MPI (distributed memory)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15-Intro-Cuda/cuda.html">15. Ref</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15-Intro-Slurm/Slurm.html">16. HPC resource manager: Slurm</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/iluvatar1/IntroSciCompHPC-2024-1s/master?urlpath=lab/tree/12-IntroHPC/ParallelProgramming-Intro.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/iluvatar1/IntroSciCompHPC-2024-1s/blob/master/github/iluvatar1/IntroSciCompHPC-2024-1s/blob/master/12-IntroHPC/ParallelProgramming-Intro.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/iluvatar1/IntroSciCompHPC-2024-1s" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/iluvatar1/IntroSciCompHPC-2024-1s/issues/new?title=Issue%20on%20page%20%2F12-IntroHPC/ParallelProgramming-Intro.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/12-IntroHPC/ParallelProgramming-Intro.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to High Performance Computing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">12.1. Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-parallel-metrics">12.2. Basics of parallel metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-overview-of-a-cluster-resources-and-use">12.3. Practical overview of a cluster resources and use</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openmp-shared-memory">12.4. Openmp, shared memory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">12.4.1. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mpi-distributed-memory">12.5. MPI, distributed memory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-parallelization-farm-task-and-gnu-parallel-or-xargs">12.6. Simple parallelization: farm task and gnu parallel or xargs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-gnu-parallel-to-run-several-matmul-and-compute-metrics">12.6.1. Using gnu parallel to run several matmul and compute metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#threads-from-c-11">12.7. Threads from c++11</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">12.7.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-algorithms-in-c">12.8. Parallel algorithms in c++</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-gpu-programming-intro">12.9. <span class="todo TODO">TODO</span> Gpu Programming intro</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup-for-cuda">12.9.1. Environment setup for cuda</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-cuda-intro">12.9.2. <span class="todo TODO">TODO</span> Cuda intro</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-openmp-offload-to-gpu">12.9.3. <span class="todo TODO">TODO</span> Openmp offload to gpu</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-openacc-intro">12.9.4. <span class="todo TODO">TODO</span> OpenACC intro</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-high-performance-computing">
<h1><span class="section-number">12. </span>Introduction to High Performance Computing<a class="headerlink" href="#introduction-to-high-performance-computing" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=PwI0tJHJOlo">https://www.youtube.com/watch?v=PwI0tJHJOlo</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=WQTrA4-9ZXk">https://www.youtube.com/watch?v=WQTrA4-9ZXk</a></p></li>
<li><p><a class="reference external" href="https://www.hpc.temple.edu/mhpc/hpc-technology/">https://www.hpc.temple.edu/mhpc/hpc-technology/</a></p></li>
<li><p><a class="github reference external" href="https://github.com/trevor-vincent/awesome-high-performance-computing">trevor-vincent/awesome-high-performance-computing</a></p></li>
<li><p><a class="reference external" href="https://viralinstruction.com/posts/hardware/">https://viralinstruction.com/posts/hardware/</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=Qlv5pB6u534">https://www.youtube.com/watch?v=Qlv5pB6u534</a> (Moore law)</p></li>
<li><p><a class="reference external" href="https://news.ycombinator.com/item?id=36318280">https://news.ycombinator.com/item?id=36318280</a></p></li>
<li><p><a class="reference external" href="https://apptainer.org/docs/user/main/index.html">https://apptainer.org/docs/user/main/index.html</a></p></li>
<li><p><a class="reference external" href="https://www.archer.ac.uk/training/online/index.php#IntroHPC">https://www.archer.ac.uk/training/online/index.php#IntroHPC</a></p></li>
<li><p><a class="reference external" href="https://www.archer.ac.uk/training/courses/index.php#hands_on_intro">https://www.archer.ac.uk/training/courses/index.php#hands_on_intro</a></p></li>
<li><p><a class="reference external" href="https://www.archer.ac.uk/training/online/driving_test.php">https://www.archer.ac.uk/training/online/driving_test.php</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=_h55hwpLwoE&amp;amp;list=PLD0xgZGaUd1IV8VgXb1ggOLkEv19JmZiP">https://www.youtube.com/watch?v=_h55hwpLwoE&amp;list=PLD0xgZGaUd1IV8VgXb1ggOLkEv19JmZiP</a></p></li>
<li><p><a class="reference external" href="https://epcced.github.io/hpc-intro/">https://epcced.github.io/hpc-intro/</a></p></li>
<li><p><a class="reference external" href="https://www.ipht.fr/Pisp/gregoire.misguich/pp.php">https://www.ipht.fr/Pisp/gregoire.misguich/pp.php</a></p></li>
<li><p>https://www.sdsc.edu/services/service_rates_summary.html</p></li>
</ul>
<p>EPCC PRACE Training</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.archer2.ac.uk/training/#upcoming-training">https://www.archer2.ac.uk/training/#upcoming-training</a></p></li>
<li><p><a class="reference external" href="https://www.archer2.ac.uk/training/courses/211202-package-users/#materials">https://www.archer2.ac.uk/training/courses/211202-package-users/#materials</a></p></li>
<li><p><a class="reference external" href="https://www.quia.com/quiz/8151816.html">https://www.quia.com/quiz/8151816.html</a></p></li>
<li><p><a class="reference external" href="https://www.archer2.ac.uk/training/courses/210000-openmp-self-service/">https://www.archer2.ac.uk/training/courses/210000-openmp-self-service/</a></p></li>
<li><p><a class="reference external" href="https://www.archer2.ac.uk/training/courses/210000-mpi-self-service/">https://www.archer2.ac.uk/training/courses/210000-mpi-self-service/</a></p></li>
<li><p><a class="reference external" href="https://www.archer2.ac.uk/training/materials/">https://www.archer2.ac.uk/training/materials/</a></p></li>
</ul>
<p>Reference Materials</p>
<p>See presentations <code class="docutils literal notranslate"><span class="pre">hpc-intro.pdf</span></code>, <code class="docutils literal notranslate"><span class="pre">07-HPC-Distributed.pdf</span></code> and
<code class="docutils literal notranslate"><span class="pre">07-Parallel-general-metrics.pdf</span></code> . Special care to metrics.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://hpc.llnl.gov/documentation/tutorials">https://hpc.llnl.gov/documentation/tutorials</a></p></li>
</ul>
<p>Debuggers:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.cs.uoregon.edu/research/tau/home.php">http://www.cs.uoregon.edu/research/tau/home.php</a></p></li>
<li><p><a class="reference external" href="https://vampir.eu/">https://vampir.eu/</a></p></li>
</ul>
<section id="introduction">
<h2><span class="section-number">12.1. </span>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>There is a point where a serial version of our code is not the most
optimal way to exploit our computational resources (but it might be in
the case of embarrassingly parallel problems where you can just run
several programs at once). For instance, you might want to use all the
cores on your multicore system, ideally reducing the execution time, or
you need to explore larger system sizes that could consume a lot of
memory or need too much time.</p>
<p>Typically, <a class="reference external" href="https://en.wikipedia.org/wiki/Moore%27s_law?useskin=vector">Moore’s
law</a> allowed
to wait for a bit in order to get a better machine so your algorithms
will run faster.</p>
<p><a class="reference external" href="https://ourworldindata.org/uploads/2020/11/Transistor-Count-over-time.png">https://ourworldindata.org/uploads/2020/11/Transistor-Count-over-time.png</a></p>
<p>But due to physics limitation and power considerations, it is now
typical to have
<a class="reference external" href="https://en.wikipedia.org/wiki/Multi-core_processor?useskin=vector">multicore</a>
systems</p>
<p><a class="reference external" href="https://i.stack.imgur.com/fRJgk.png">https://i.stack.imgur.com/fRJgk.png</a></p>
<p>Recently, power considerations are being more and more relevant:</p>
<ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Performance_per_watt?useskin=vector">https://en.wikipedia.org/wiki/Performance_per_watt?useskin=vector</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Koomey%27s_law?useskin=vector">https://en.wikipedia.org/wiki/Koomey’s_law?useskin=vector</a></p></li>
<li><p><a class="reference external" href="https://www.apple.com/newsroom/2022/03/apple-unveils-m1-ultra-the-worlds-most-powerful-chip-for-a-personal-computer/">https://www.apple.com/newsroom/2022/03/apple-unveils-m1-ultra-the-worlds-most-powerful-chip-for-a-personal-computer/</a></p></li>
<li><p><a class="reference external" href="https://www.extremetech.com/extreme/328541-the-apple-m1-pro-and-m1-maxs-power-efficiency-should-rattle-intel-amd">https://www.extremetech.com/extreme/328541-the-apple-m1-pro-and-m1-maxs-power-efficiency-should-rattle-intel-amd</a>)</p>
<p><a class="reference external" href="https://i.extremetech.com/imagery/content-types/07CyoCCWMzGjurj8zpuiYO4/images-2.jpg">https://i.extremetech.com/imagery/content-types/07CyoCCWMzGjurj8zpuiYO4/images-2.jpg</a></p>
</li>
</ul>
<p>At the same time, the computational problems size and/or complexity has
been steadily increasing in time, requiring <a class="reference external" href="https://en.wikipedia.org/wiki/Distributed_computing?useskin=vector">distributed
computing</a>
techniques.</p>
<p><a class="reference external" href="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Distributed-parallel.svg/600px-Distributed-parallel.svg.png">https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Distributed-parallel.svg/600px-Distributed-parallel.svg.png</a></p>
<p>(see also
<a class="reference external" href="https://en.wikipedia.org/wiki/Flynn%27s_taxonomy?useskin=vector">https://en.wikipedia.org/wiki/Flynn’s_taxonomy?useskin=vector</a>).
Recently, besides CPU parallelization, the GPU parallelization has
become very relevant (see
<a class="reference external" href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units?useskin=vector">https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units?useskin=vector</a>
), where <a class="reference external" href="https://en.wikipedia.org/wiki/CUDA?useskin=vector">CUDA</a> ,
<a class="reference external" href="https://en.wikipedia.org/wiki/OpenACC?useskin=vector">OpenACC</a>, and
others, are the relevant technologies.</p>
<p>In our case, we will be more focused on the <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Computer_cluster&amp;amp;useskin=vector">cluster
computing</a>
aspect, while there are more
<a class="reference external" href="https://en.wikipedia.org/wiki/High-performance_computing?useskin=vector">HPC</a>
approaches, like <a class="reference external" href="https://en.wikipedia.org/wiki/Grid_computing?useskin=vector">grid
computing</a>,
<a class="reference external" href="https://en.wikipedia.org/wiki/Cloud_computing?useskin=vector">cloud
computing</a>,
and so on. One of the goals of
<a class="reference external" href="https://en.wikipedia.org/wiki/High-performance_computing?useskin=vector">HPC</a>
is to get better results faster and/or to exploit better current or
future resources.</p>
<p><a class="reference external" href="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/IBM_Blue_Gene_P_supercomputer.jpg/600px-IBM_Blue_Gene_P_supercomputer.jpg">https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/IBM_Blue_Gene_P_supercomputer.jpg/600px-IBM_Blue_Gene_P_supercomputer.jpg</a></p>
</section>
<section id="basics-of-parallel-metrics">
<h2><span class="section-number">12.2. </span>Basics of parallel metrics<a class="headerlink" href="#basics-of-parallel-metrics" title="Link to this heading">#</a></h2>
<p>But, as usual, you should always measure. All programs have a serial
part that cannot be parallelized and a parallel part than can. Using
more processors/threads can reduce only the parallel, so a 100% serial
program cannot really take advantage of a parallel system. This is known
as Amdahls law,
<a class="reference external" href="https://en.wikipedia.org/wiki/Amdahl%27s_law?useskin=vector">https://en.wikipedia.org/wiki/Amdahl’s_law?useskin=vector</a></p>
<p><a class="reference external" href="https://upload.wikimedia.org/wikipedia/commons/e/ea/AmdahlsLaw.svg">https://upload.wikimedia.org/wikipedia/commons/e/ea/AmdahlsLaw.svg</a></p>
<p>At the end, the user must also gauge its application performance.
Blindly reserve of HPC resources represent a non efficient cluster use,
and higher costs. In this regard, parallel metrics are really crucial.
The next to figures show the speedup and the parallel efficiency. As you
can see, they are limited by the hardware (and algorithms)</p>
<ul class="simple">
<li><p>Speedup:
<img alt="../_images/speedup.png" class="centerimg50" src="../_images/speedup.png" /></p></li>
<li><p>Parallel efficiency:
<img alt="../_images/efficiency.png" class="centerimg50" src="../_images/efficiency.png" /></p></li>
</ul>
</section>
<section id="practical-overview-of-a-cluster-resources-and-use">
<h2><span class="section-number">12.3. </span>Practical overview of a cluster resources and use<a class="headerlink" href="#practical-overview-of-a-cluster-resources-and-use" title="Link to this heading">#</a></h2>
<p>There are many aspects to take into account in the HPC field. If you are
a user, you should know abount the type of parallelization (shared
memory, disitributed memory, gpu programming), the type of hardware you
are using, the resource manager, the data storage and so on. The goal of
a system administrator is to make that easier, but that is not always
possible. Check the <code class="docutils literal notranslate"><span class="pre">12-12-hkhlr_quick_reference-goethe-hlr</span></code> (from
<a class="reference external" href="https://csc.uni-frankfurt.de/wiki/doku.php?id=public:start">https://csc.uni-frankfurt.de/wiki/doku.php?id=public:start</a>) for an
example of a typical cluster config and offerings.</p>
<p>These are examples from the Archer cluster at
<a class="reference external" href="https://www.archer2.ac.uk/">https://www.archer2.ac.uk/</a></p>
<p><img alt="../_images/Archer1.png" src="../_images/Archer1.png" /></p>
<img alt="../_images/Archer2.png" class="centerimg50" src="../_images/Archer2.png" />
<img alt="../_images/Archer3.png" class="centerimg50" src="../_images/Archer3.png" />
<p>In the following, we will see some basic examples for HPC, such us</p>
<ul class="simple">
<li><p>Shared memory: with openmp</p></li>
<li><p>Distributed memory: using mpi</p></li>
<li><p>Multiple processes: using gnu parallel</p></li>
<li><p>C++ threads</p></li>
<li><p>TODO C++ parallel algorithms</p></li>
</ul>
</section>
<section id="openmp-shared-memory">
<h2><span class="section-number">12.4. </span>Openmp, shared memory<a class="headerlink" href="#openmp-shared-memory" title="Link to this heading">#</a></h2>
<p>The following code shows a very simple parallelization using openmp,
which allows tu share memory and run on several threads.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;omp.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;BEFORE</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="cp">#pragma omp parallel</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Hola mundo</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;AFTER</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To activate multi-threading, compile it as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-fopenmp<span class="w"> </span>codes/openmp.cpp
</pre></div>
</div>
<p>To run it, you can control the number of threads using the environment
variable <code class="docutils literal notranslate"><span class="pre">OMP_NUM_THREADS</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-fopenmp<span class="w"> </span>codes/openmp.cpp
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Running with 2 threads&quot;</span>
<span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">2</span><span class="w"> </span>./a.out
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Running with 4 threads&quot;</span>
<span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">4</span><span class="w"> </span>./a.out
</pre></div>
</div>
<section id="exercises">
<h3><span class="section-number">12.4.1. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Modify the previous exercise to identify the thread which is
printing. Find a function to get the “thread id”.</p></li>
<li><p>Besides the thread id, print the number of threads and the hostname.
Print the number of threads outside the parallel region. Does that
make sense?</p></li>
</ol>
</section>
</section>
<section id="mpi-distributed-memory">
<h2><span class="section-number">12.5. </span>MPI, distributed memory<a class="headerlink" href="#mpi-distributed-memory" title="Link to this heading">#</a></h2>
<p>MPI, the Message Passing Interface, is a library API that allows process
to interchange data in a distributed memory context. It is more comple
that openmp, but also opens the door to a greater scale since we can use
many computers, increasing both our computational power and memory
capacity (if done correctly and efficiently).</p>
<p>The following shows the basic structure of a MPI program. It creates
several <strong>processes</strong> that can communicate with each other, and can be
run in multiple machines (for an introduction, see:
<a class="reference external" href="https://mpitutorial.com/tutorials/mpi-introduction/">https://mpitutorial.com/tutorials/mpi-introduction/</a>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;mpi.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">**</span><span class="w"> </span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Initialize the MPI environment</span>
<span class="w">    </span><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the number of processes</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">np</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">np</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the rank of the process</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">pid</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">pid</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the name of the processor</span>
<span class="w">    </span><span class="kt">char</span><span class="w"> </span><span class="n">processor_name</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">name_len</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">processor_name</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name_len</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Print off a hello world message</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello world from processor %s, rank %d out of %d processes</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
<span class="w">           </span><span class="n">processor_name</span><span class="p">,</span><span class="w"> </span><span class="n">pid</span><span class="p">,</span><span class="w"> </span><span class="n">np</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Finalize the MPI environment.</span>
<span class="w">    </span><span class="n">MPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
<p>You can compile it as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpic++<span class="w">  </span>mpi.cpp
</pre></div>
</div>
<p>(If you want to see all the flags, use <code class="docutils literal notranslate"><span class="pre">mpic++</span> <span class="pre">--showme</span></code>)</p>
<p>And now run it as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-np<span class="w"> </span><span class="m">4</span><span class="w"> </span>./a.out
</pre></div>
</div>
<p>You can also specifiy different machines to run on, but you will need to
have configured passwordless access to those machines.</p>
</section>
<section id="simple-parallelization-farm-task-and-gnu-parallel-or-xargs">
<h2><span class="section-number">12.6. </span>Simple parallelization: farm task and gnu parallel or xargs<a class="headerlink" href="#simple-parallelization-farm-task-and-gnu-parallel-or-xargs" title="Link to this heading">#</a></h2>
<p>Sometimes you do not need to actually parallelize your code, but to run
it with many parameters combination. Let’s assume that we have a task
that depend on one parameter and can be executed independent of other
parameters. It can be a very complex program, but for now it will be
just a very simple bash instructions that prints a value. Save the
following code in a bash script (like <code class="docutils literal notranslate"><span class="pre">script.sh</span></code>) that will use the
<code class="docutils literal notranslate"><span class="pre">stress</span></code> command to stress a single core</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># file: script.sh</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;First arg: </span><span class="si">${</span><span class="nv">1</span><span class="si">}</span><span class="s2">&quot;</span>
stress<span class="w"> </span>-t<span class="w"> </span><span class="m">10</span><span class="w"> </span>-c<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="c1"># stress one core</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Stress test done&quot;</span>
</pre></div>
</div>
<p>When it is executed, it just prints the first argument</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>codes/script.sh<span class="w"> </span><span class="m">23</span>
</pre></div>
</div>
<p>What if we want to do execute this task for 4 different arguments? we
will just do it sequentially:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>date<span class="w"> </span>+<span class="s2">&quot;%H-%M-%S&quot;</span>
bash<span class="w"> </span>codes/script.sh<span class="w"> </span><span class="m">23</span>
bash<span class="w"> </span>codes/script.sh<span class="w"> </span><span class="m">42</span>
bash<span class="w"> </span>codes/script.sh<span class="w"> </span><span class="m">10</span>
bash<span class="w"> </span>codes/script.sh<span class="w"> </span><span class="m">57</span>
date<span class="w"> </span>+<span class="s2">&quot;%H-%M-%S&quot;</span>
</pre></div>
</div>
<p>40 seconds in total. Remember that this example is very simple, but
assume that the script is a very large task. Then, the previous task
will take four times the time of a simple task. What if we have a
machine with four possible threads? it will be useful to run all the
commands in parallel. To do so you might just put them in the background
with the <code class="docutils literal notranslate"><span class="pre">&amp;</span></code> character at the end. But what will happen if you need to
run 7 different arguments and you have only 4 threads? then it would be
not optimal to have all of them running at tha same time with less than
100% of cpu usage. It would be better to run 4 of them and when one of
the finishes then launch the next one and so on. To do this
programatically, you can use <code class="docutils literal notranslate"><span class="pre">gnu</span> <span class="pre">parallel</span></code>,
<a class="reference external" href="https://www.gnu.org/software/parallel/">https://www.gnu.org/software/parallel/</a> (check the tutorial in the
documentation section, or the cheatsheet,
<a class="reference external" href="https://www.gnu.org/software/parallel/parallel_cheat.pdf">https://www.gnu.org/software/parallel/parallel_cheat.pdf</a>). You can
install as <code class="docutils literal notranslate"><span class="pre">spack</span> <span class="pre">info</span> <span class="pre">parallel</span></code>, or load it with <code class="docutils literal notranslate"><span class="pre">spack</span> <span class="pre">load</span> <span class="pre">parallel</span></code>
if it not installed already. For our case, it would be very useful</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>date<span class="w"> </span>+<span class="s2">&quot;%H-%M-%S&quot;</span>
parallel<span class="w"> </span><span class="s1">&#39;bash codes/script.sh {} &#39;</span><span class="w"> </span>:::<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">42</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">57</span>
date<span class="w"> </span>+<span class="s2">&quot;%H-%M-%S&quot;</span>
</pre></div>
</div>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>08-12-25</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>23</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[83775]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-odd"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>42</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[83779]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-even"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>10</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[83781]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-odd"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>57</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[83785]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-even"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>08-12-36</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>Around 10 seconds now! Gnu parallel will detect the number of cores and
launch the process accodingly taking care of jobs distribution. Read the
manual for the many options of this powerful tool that is used even on
large clusters. For instance, try to run 7 processes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>date<span class="w"> </span>+<span class="s2">&quot;%H-%M-%S&quot;</span>
parallel<span class="w"> </span><span class="s1">&#39;bash codes/script.sh {} &#39;</span><span class="w"> </span>:::<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">42</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">57</span><span class="w"> </span><span class="m">21</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">83</span>
date<span class="w"> </span>+<span class="s2">&quot;%H-%M-%S&quot;</span>
</pre></div>
</div>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>08-13-20</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>23</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84082]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-odd"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>42</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84086]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-even"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>10</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84088]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-odd"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>57</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84091]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-even"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>21</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84161]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-odd"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>8</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84165]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-even"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>First</p></td>
<td><p>arg:</p></td>
<td><p>83</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>stress:</p></td>
<td><p>info:</p></td>
<td><p>[84168]</p></td>
<td><p>dispatching</p></td>
<td><p>hogs:</p></td>
<td><p>1</p></td>
<td><p>cpu,</p></td>
<td><p>0</p></td>
<td><p>io,</p></td>
<td><p>0</p></td>
<td><p>vm,</p></td>
<td><p>0</p></td>
<td><p>hdd</p></td>
</tr>
<tr class="row-odd"><td><p>Stress</p></td>
<td><p>test</p></td>
<td><p>done</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>08-13-41</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>You can play with the <code class="docutils literal notranslate"><span class="pre">-j</span> <span class="pre">n</span></code> flag to control how many jobs to run with
parallel. By default it uses all possible threads</p>
<section id="using-gnu-parallel-to-run-several-matmul-and-compute-metrics">
<h3><span class="section-number">12.6.1. </span>Using gnu parallel to run several matmul and compute metrics<a class="headerlink" href="#using-gnu-parallel-to-run-several-matmul-and-compute-metrics" title="Link to this heading">#</a></h3>
<p>Now let’s use the previous matmul with eigen and blas exercise to show
how to use parallel to run several matrix sizes at the same time and
also to compute some parallel metrics. The code is</p>
<p>We have two goals:</p>
<ol class="arabic simple">
<li><p>To compute the wall time as a function of the matrix size (strong
scaling, changing problem size), using blas.</p></li>
<li><p>To compute the speedup and parallel efficiency for a fixed matrix
size.</p></li>
</ol>
<p>In the first case we will just use parallel to run as many simulations
as possible. In the second case we will compute some metrics to check
when is our code the most efficient.</p>
<p>It is assumed that you have blas with spack, so you can load it as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>spack<span class="w"> </span>load<span class="w"> </span>openblas
</pre></div>
</div>
<p>or might have to install it using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>spack<span class="w"> </span>install<span class="w"> </span>openblas<span class="w"> </span><span class="nv">threads</span><span class="o">=</span>openmp<span class="w"> </span><span class="nv">cxxflags</span><span class="o">=</span><span class="s2">&quot;-O3&quot;</span><span class="w"> </span><span class="nv">cflags</span><span class="o">=</span><span class="s2">&quot;-O3&quot;</span><span class="w"> </span><span class="nv">target</span><span class="o">=</span>x86_64
</pre></div>
</div>
<p>(the last flag is just to have the same target independent of the actual
machine, like the conditions we have in the computer room)</p>
<ol class="arabic">
<li><p>Strong scaling: Time as a function of matriz size, one thread,
eigen + blas</p>
<p>Naively, we could just run the program serially for each matriz
size, but if we are in computer with multiple cores/threads it would
be better if we ran as many parameters as possible (adapt the
following instructions to your case):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#source $HOME/repos/spack/share/spack/setup-env.sh</span>
spack<span class="w"> </span>load<span class="w"> </span>openblas
<span class="c1">#g++ -fopenmp -O3 -I $CMAKE_PREFIX_PATH/include -L $CMAKE_PREFIX_PATH/lib eigen-matmul.cpp -DEIGEN_USE_BLAS -lopenblas -o eigen_blas.x</span>
g++<span class="w"> </span>-fopenmp<span class="w"> </span>-O3<span class="w">  </span>eigen-matmul.cpp<span class="w"> </span>-DEIGEN_USE_BLAS<span class="w"> </span>-lopenblas<span class="w"> </span>-o<span class="w"> </span>eigen_blas.x
parallel<span class="w"> </span><span class="s1">&#39;OMP_NUM_THREADS=1 ./eigen_blas.x {} 10 2&gt;/dev//null&#39;</span><span class="w"> </span>:::<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="m">700</span><span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="m">2000</span><span class="w"> </span>5000w
</pre></div>
</div>
<p>Check that your programs are running in parallel, as expected.</p>
<ol class="arabic">
<li><p>Exercise: Strong scaling for eigen eigenvectors</p>
<p>With the following code, compute the strong scaling of eigen
when computing eigenvectors with the more general method:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;eigen3/Eigen/Dense&gt;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">solve_eigensystem</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">&amp;</span><span class="n">time</span><span class="p">);</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">arg</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span><span class="w"> </span><span class="c1">// Matrix size</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span><span class="w"> </span><span class="c1">// Repetitions</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">S</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]);</span><span class="w"> </span><span class="c1">// seed</span>
<span class="w">  </span><span class="n">srand</span><span class="p">(</span><span class="n">S</span><span class="p">);</span>

<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">totaltime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">auxtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">irep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">irep</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">R</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">irep</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">solve_eigensystem</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">auxtime</span><span class="p">);</span>
<span class="w">    </span><span class="n">totaltime</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">auxtime</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\t</span><span class="s">&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">totaltime</span><span class="o">/</span><span class="n">R</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>

<span class="w"> </span><span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">solve_eigensystem</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">&amp;</span><span class="n">time</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="n">aux</span><span class="p">;</span>
<span class="w">  </span><span class="n">Eigen</span><span class="o">::</span><span class="n">MatrixXd</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Eigen</span><span class="o">::</span><span class="n">MatrixXd</span><span class="o">::</span><span class="n">Random</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">  </span><span class="n">Eigen</span><span class="o">::</span><span class="n">SelfAdjointEigenSolver</span><span class="o">&lt;</span><span class="n">Eigen</span><span class="o">::</span><span class="n">MatrixXd</span><span class="o">&gt;</span><span class="w"> </span><span class="n">eigensolver</span><span class="p">(</span><span class="n">A</span><span class="p">);</span>
<span class="w">  </span><span class="n">aux</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eigensolver</span><span class="p">.</span><span class="n">eigenvalues</span><span class="p">()(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">clog</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;The first eigenvalue of A is:</span><span class="se">\n</span><span class="s">&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">aux</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="p">;</span>
<span class="w">  </span><span class="n">time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">count</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile como</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-O3<span class="w"> </span>eigen-eigenvectors.cpp<span class="w">  </span>-o<span class="w"> </span>eigen.x
</pre></div>
</div>
<p>Ejecute como</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./eigen.x<span class="w"> </span>M<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="m">2</span>&gt;/dev/null
</pre></div>
</div>
<p>debe cambiar M, matriz size.</p>
<p>Datos de ejemplo (dependen de la maquina, pero las relaciones
entre ellos deben ser similares):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">10</span><span class="w">      </span><span class="m">9</span>.7568e-06
<span class="m">20</span><span class="w">      </span><span class="m">3</span>.55734e-05
<span class="m">50</span><span class="w">      </span><span class="m">0</span>.000312481
<span class="m">80</span><span class="w">      </span><span class="m">0</span>.000890043
...
<span class="m">2700</span><span class="w">    </span><span class="m">72</span>.8078
<span class="m">3000</span><span class="w">    </span><span class="m">81</span>.0619
</pre></div>
</div>
<p>Plot the data ad analyze.</p>
</li>
</ol>
</li>
<li><p>Weak scaling: number of threads and parallel metrics</p>
<p>Here we will compute some key parallel metrics that inform about the
efficiency of our code when running in parallel. Now you do not want
to use gnu parallel since you have a variable number of thredas per
process</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span><span class="nv">$HOME</span>/repos/spack/share/spack/setup-env.sh
spack<span class="w"> </span>load<span class="w"> </span>openblas
<span class="c1">#g++ -fopenmp -O3 -I $CMAKE_PREFIX_PATH/include -L $CMAKE_PREFIX_PATH/lib eigen-matmul.cpp -DEIGEN_USE_BLAS -lopenblas -o eigen_blas.x</span>
g++<span class="w"> </span>-fopenmp<span class="w"> </span>-O3<span class="w"> </span>eigen-matmul.cpp<span class="w"> </span>-DEIGEN_USE_BLAS<span class="w"> </span>-lopenblas<span class="w"> </span>-o<span class="w"> </span>eigen_blas.x
parallel<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="s1">&#39;echo -n &quot;{}  &quot;; OMP_NUM_THREADS={} ./eigen_blas.x 4000 10 2&gt;/dev//null&#39;</span><span class="w"> </span>:::<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="m">6</span><span class="w"> </span><span class="m">7</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">9</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="m">11</span><span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">14</span><span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">16</span>
</pre></div>
</div>
<p>The following is data obtained from a run in a 8core/16threads
computer, running only with eigen</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">1</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">6</span>.75223<span class="w"> </span><span class="m">0</span>.00290168<span class="w">      </span><span class="m">6</span>.75225<span class="w"> </span><span class="m">0</span>.0029001
<span class="m">2</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">3</span>.52052<span class="w"> </span><span class="m">0</span>.00405504<span class="w">      </span><span class="m">7</span>.01616<span class="w"> </span><span class="m">0</span>.00819132
<span class="m">3</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">2</span>.40281<span class="w"> </span><span class="m">0</span>.0117795<span class="w">       </span><span class="m">7</span>.15847<span class="w"> </span><span class="m">0</span>.0355119
<span class="m">4</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">1</span>.85186<span class="w"> </span><span class="m">0</span>.0049013<span class="w">       </span><span class="m">7</span>.33257<span class="w"> </span><span class="m">0</span>.0187681
<span class="m">5</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">1</span>.72682<span class="w"> </span><span class="m">0</span>.176218<span class="w">        </span><span class="m">8</span>.53451<span class="w"> </span><span class="m">0</span>.880953
<span class="m">6</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">1</span>.65921<span class="w"> </span><span class="m">0</span>.00946933<span class="w">      </span><span class="m">9</span>.83127<span class="w"> </span><span class="m">0</span>.0574367
<span class="m">7</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">1</span>.52068<span class="w"> </span><span class="m">0</span>.00538196<span class="w">      </span><span class="m">10</span>.4943<span class="w"> </span><span class="m">0</span>.0370317
<span class="m">8</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">1</span>.39755<span class="w"> </span><span class="m">0</span>.0326183<span class="w">       </span><span class="m">11</span>.006<span class="w">  </span><span class="m">0</span>.260568
<span class="m">9</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">2</span>.26355<span class="w"> </span><span class="m">0</span>.00254841<span class="w">      </span><span class="m">19</span>.9546<span class="w"> </span><span class="m">0</span>.0452903
<span class="m">10</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">2</span>.04808<span class="w"> </span><span class="m">0</span>.00732663<span class="w">      </span><span class="m">20</span>.0991<span class="w"> </span><span class="m">0</span>.0807175
<span class="m">11</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">2</span>.00821<span class="w"> </span><span class="m">0</span>.00876695<span class="w">      </span><span class="m">21</span>.7043<span class="w"> </span><span class="m">0</span>.104527
<span class="m">12</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">1</span>.76768<span class="w"> </span><span class="m">0</span>.0276189<span class="w">       </span><span class="m">20</span>.834<span class="w">  </span><span class="m">0</span>.324801
<span class="m">13</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">1</span>.77771<span class="w"> </span><span class="m">0</span>.00686642<span class="w">      </span><span class="m">22</span>.7412<span class="w"> </span><span class="m">0</span>.0887671
<span class="m">14</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">1</span>.59293<span class="w"> </span><span class="m">0</span>.0116353<span class="w">       </span><span class="m">21</span>.9208<span class="w"> </span><span class="m">0</span>.213236
<span class="m">15</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">1</span>.56692<span class="w"> </span><span class="m">0</span>.00829185<span class="w">      </span><span class="m">23</span>.1334<span class="w"> </span><span class="m">0</span>.121202
<span class="m">16</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">1</span>.49262<span class="w"> </span><span class="m">0</span>.0321579<span class="w">       </span><span class="m">23</span>.3921<span class="w"> </span><span class="m">0</span>.417985
</pre></div>
</div>
<p>And these are with running with eigen+blas</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">1</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">1</span>.76345<span class="w"> </span><span class="m">0</span>.00750705<span class="w">      </span><span class="m">1</span>.76345<span class="w"> </span><span class="m">0</span>.0075023
<span class="m">2</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.930922<span class="w">        </span><span class="m">0</span>.00450842<span class="w">      </span><span class="m">1</span>.83688<span class="w"> </span><span class="m">0</span>.00900039
<span class="m">3</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.666528<span class="w">        </span><span class="m">0</span>.0122499<span class="w">       </span><span class="m">1</span>.94996<span class="w"> </span><span class="m">0</span>.0365303
<span class="m">4</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.523076<span class="w">        </span><span class="m">0</span>.00175201<span class="w">      </span><span class="m">2</span>.01795<span class="w"> </span><span class="m">0</span>.00654245
<span class="m">5</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.442096<span class="w">        </span><span class="m">0</span>.00226719<span class="w">      </span><span class="m">2</span>.1107<span class="w">  </span><span class="m">0</span>.0108692
<span class="m">6</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.394103<span class="w">        </span><span class="m">0</span>.00867531<span class="w">      </span><span class="m">2</span>.23982<span class="w"> </span><span class="m">0</span>.0513271
<span class="m">7</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.371224<span class="w">        </span><span class="m">0</span>.000725666<span class="w">     </span><span class="m">2</span>.44876<span class="w"> </span><span class="m">0</span>.00691333
<span class="m">8</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.35202<span class="w"> </span><span class="m">0</span>.00564542<span class="w">      </span><span class="m">2</span>.64095<span class="w"> </span><span class="m">0</span>.0441576
<span class="m">9</span><span class="w">  </span><span class="m">4000</span><span class="w"> </span><span class="m">0</span>.53266<span class="w"> </span><span class="m">0</span>.00218486<span class="w">      </span><span class="m">4</span>.59061<span class="w"> </span><span class="m">0</span>.02803
<span class="m">10</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.496156<span class="w">        </span><span class="m">0</span>.00207424<span class="w">      </span><span class="m">4</span>.73416<span class="w"> </span><span class="m">0</span>.0281744
<span class="m">11</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.461317<span class="w">        </span><span class="m">0</span>.00102704<span class="w">      </span><span class="m">4</span>.82462<span class="w"> </span><span class="m">0</span>.0111843
<span class="m">12</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.550406<span class="w">        </span><span class="m">0</span>.0431109<span class="w">       </span><span class="m">6</span>.32975<span class="w"> </span><span class="m">0</span>.518631
<span class="m">13</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.514583<span class="w">        </span><span class="m">0</span>.0119228<span class="w">       </span><span class="m">6</span>.38601<span class="w"> </span><span class="m">0</span>.144949
<span class="m">14</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.494073<span class="w">        </span><span class="m">0</span>.0166192<span class="w">       </span><span class="m">6</span>.58912<span class="w"> </span><span class="m">0</span>.231588
<span class="m">15</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.484151<span class="w">        </span><span class="m">0</span>.0121776<span class="w">       </span><span class="m">6</span>.90909<span class="w"> </span><span class="m">0</span>.179303
<span class="m">16</span><span class="w">  </span><span class="m">4000</span><span class="w">        </span><span class="m">0</span>.493364<span class="w">        </span><span class="m">0</span>.0316198<span class="w">       </span><span class="m">7</span>.45327<span class="w"> </span><span class="m">0</span>.429279
</pre></div>
</div>
<p>The two more important parallel metric efficiency.</p>
<p>The speed up is defined as</p>
<p>where <span class="math notranslate nohighlight">\(T_1\)</span> is the reference time with one thread, and <span class="math notranslate nohighlight">\(T_n\)</span> with n
threads. For a perfect scaling, <span class="math notranslate nohighlight">\(T_n = T_1/n\)</span>, so
<span class="math notranslate nohighlight">\(S_{\rm theo}(n) = n\)</span>. This does not occur always and depend on the
actual machine, the communication patterns and so on. In the
following we will use <span class="math notranslate nohighlight">\(T_1 = 6.75223\)</span> for eigen and <span class="math notranslate nohighlight">\(T_1 = 1.76345\)</span>
for eigen+blas.</p>
<p>The parallel efficiency measures roughly how efficiently we are
using all the threads. It is defined as</p>
<p>and, therefore, theoretically it is equal to 1.</p>
<p>To easily create the data we need, we could use a spreadsheet or
better, the command line</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>awk<span class="w"> </span><span class="s1">&#39;{print $1, 6.75223/$3, 6.75223/$3/$1 }&#39;</span><span class="w"> </span>codes/eigen.txt<span class="w"> </span>&gt;<span class="w"> </span>codes/eigen_metrics.txt
awk<span class="w"> </span><span class="s1">&#39;{print $1, 1.76345/$3, 1.76345/$3/$1 }&#39;</span><span class="w"> </span>codes/eigen_blas.txt<span class="w"> </span>&gt;<span class="w"> </span>codes/eigen_blas_metrics.txt
</pre></div>
</div>
<p>Then we can plot and analize</p>
<div class="highlight-gnuplot notranslate"><div class="highlight"><pre><span></span><span class="k">set</span><span class="w"> </span><span class="nb">term</span><span class="w"> </span><span class="n">png</span><span class="w"> </span><span class="n">enhaced</span><span class="w"> </span><span class="n">giant</span><span class="c">#; set out &#39;tmpspeedup.png&#39;</span>
<span class="k">set</span><span class="w"> </span><span class="nb">key</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="n">t</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="nb">xlabel</span><span class="w"> </span><span class="s">&#39;nthreads&#39;</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="nb">ylabel</span><span class="w"> </span><span class="s">&#39;Parallel speedup&#39;</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="nb">title</span><span class="w"> </span><span class="s">&#39;Computer with 8cores/16threads&#39;</span>
<span class="k">plot</span><span class="w"> </span><span class="p">[</span><span class="o">:</span><span class="mi">17</span><span class="p">][</span><span class="o">:</span><span class="p">]</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">lt</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="nb">t</span><span class="w"> </span><span class="s">&#39;theo&#39;</span><span class="o">,</span><span class="w"> </span><span class="s">&#39;codes/eigen_metrics.txt&#39;</span><span class="w"> </span><span class="nb">u</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">2</span><span class="w"> </span><span class="nb">w</span><span class="w"> </span><span class="n">lp</span><span class="w"> </span><span class="nb">t</span><span class="w"> </span><span class="s">&#39;eigen&#39;</span><span class="o">,</span><span class="w"> </span><span class="s">&#39;codes/eigen_blas_metrics.txt&#39;</span><span class="w">  </span><span class="nb">u</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">2</span><span class="w"> </span><span class="nb">w</span><span class="w"> </span><span class="n">lp</span><span class="w"> </span><span class="nb">t</span><span class="w"> </span><span class="s">&#39;eigen+blas&#39;</span>
</pre></div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/6fbcecbcd65ae59253bb1a26324a21a8/speedup.png"><span class="xref download myst">Speedup</span></a></p>
<div class="highlight-gnuplot notranslate"><div class="highlight"><pre><span></span><span class="c">#set term png; set out &#39;efficiency.png&#39;</span>
<span class="k">set</span><span class="w"> </span><span class="nb">key</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="n">b</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="nb">xlabel</span><span class="w"> </span><span class="s">&#39;nthreads&#39;</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="nb">ylabel</span><span class="w"> </span><span class="s">&#39;Parallel efficiency&#39;</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="nb">title</span><span class="w"> </span><span class="s">&#39;Computer with 8cores/16threads&#39;</span>
<span class="k">plot</span><span class="w"> </span><span class="p">[</span><span class="o">:</span><span class="mi">17</span><span class="p">][</span><span class="mi">-0</span><span class="mf">.1</span><span class="o">:</span><span class="mf">1.1</span><span class="p">]</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">lt</span><span class="w"> </span><span class="mi">-1</span><span class="o">,</span><span class="w"> </span><span class="s">&#39;codes/eigen_metrics.txt&#39;</span><span class="w"> </span><span class="nb">u</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="w"> </span><span class="nb">w</span><span class="w"> </span><span class="n">lp</span><span class="w"> </span><span class="nb">t</span><span class="w"> </span><span class="s">&#39;eigen&#39;</span><span class="o">,</span><span class="w"> </span><span class="s">&#39;codes/eigen_blas_metrics.txt&#39;</span><span class="w">  </span><span class="nb">u</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="w"> </span><span class="nb">w</span><span class="w"> </span><span class="n">lp</span><span class="w"> </span><span class="nb">t</span><span class="w"> </span><span class="s">&#39;eigen+blas&#39;</span><span class="o">,</span><span class="w"> </span><span class="mf">0.6</span><span class="w"> </span><span class="n">lt</span><span class="w"> </span><span class="mi">4</span>
</pre></div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/b599638c93116288373e4cbc7e3a8de1/efficiency.png"><span class="xref download myst">Efficiency</span></a></p>
<p>Normally, if you want to buy some cloud services to run your code,
you should use threads that give equal or above 60-70% efficiency.</p>
</li>
</ol>
</section>
</section>
<section id="threads-from-c-11">
<h2><span class="section-number">12.7. </span>Threads from c++11<a class="headerlink" href="#threads-from-c-11" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">c++11</span></code> standard included, among many other usefull things, the use
a <strong>thread</strong>. A thread is a lightweight process that can be launched in
parallel with other threads from a parent process. In the following we
will see some very simple examples since at the end we will focus mainly
on OpenMP (where threads are the key and the memory is shared) and MPI
(where processes are the basic unit and memory is distributed).</p>
<p>The following example are based on</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.cppreference.com/w/cpp/thread">https://en.cppreference.com/w/cpp/thread</a></p></li>
<li><p><a class="reference external" href="https://www.classes.cs.uchicago.edu/archive/2013/spring/12300-1/labs/lab6/">https://www.classes.cs.uchicago.edu/archive/2013/spring/12300-1/labs/lab6/</a></p></li>
</ul>
<p>The following example shows how to create a thread from a given process,
and its output:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="p">);</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">th1</span><span class="p">(</span><span class="o">&amp;</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">th2</span><span class="p">(</span><span class="o">&amp;</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="mi">200</span><span class="p">);</span>
<span class="w">    </span><span class="n">th1</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Outside thread&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">th2</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inside thread &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="o">::</span><span class="n">id</span><span class="w"> </span><span class="n">this_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">get_id</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;This is thread_id: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">this_id</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile it as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>thread-v1.cpp
</pre></div>
</div>
<p>The folowwing is an example of the output:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Inside</p></td>
<td><p>thread</p></td>
<td><p>Inside</p></td>
<td><p>thread</p></td>
<td><p>100200</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>This</p></td>
<td><p>is</p></td>
<td><p>thread<sub>id</sub>:</p></td>
<td><p>This</p></td>
<td><p>is</p></td>
<td><p>thread<sub>id</sub>:</p></td>
<td><p>0x700003c34000</p></td>
</tr>
<tr class="row-odd"><td><p>0x700003cb7000</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Outside</p></td>
<td><p>thread</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>Run it several times, you will obtain different outputs, many times they
will be mangled. Why? because the threads are running in parallel and
their output is not independent of each other, not synced.</p>
<p>To check that we are really running two threads, let’s increase the
computational effort inside function <code class="docutils literal notranslate"><span class="pre">func</span></code> and then, while the program
is running, use top or htop to check what is running on your computer.
Notice that the cpu use percentage is around <code class="docutils literal notranslate"><span class="pre">200%</span></code>:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cmath&gt;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">nsecs</span><span class="p">);</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">secs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">th1</span><span class="p">(</span><span class="o">&amp;</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="n">secs</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">th2</span><span class="p">(</span><span class="o">&amp;</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="mi">200</span><span class="p">,</span><span class="w"> </span><span class="n">secs</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">th3</span><span class="p">(</span><span class="o">&amp;</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="mi">300</span><span class="p">,</span><span class="w"> </span><span class="n">secs</span><span class="p">);</span>
<span class="w">    </span><span class="n">th1</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Outside thread&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">th2</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="n">th3</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">nsecs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Inside thread &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="n">nsecs</span><span class="p">));</span><span class="w"> </span><span class="c1">// make this sleep, does not consume a lot of resources</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">ii</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">ii</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100000000</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">ii</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">x</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">fabs</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">std</span><span class="o">::</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mf">3.4455</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Getting out of thread &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The folowwing is an example of the output:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Inside</p></td>
<td><p>thread</p></td>
<td><p>Inside</p></td>
<td><p>thread</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p>200</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Getting</p></td>
<td><p>out</p></td>
<td><p>of</p></td>
<td><p>thread</p></td>
<td><p>9387820000.0</p></td>
</tr>
<tr class="row-odd"><td><p>Outside</p></td>
<td><p>thread</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Getting</p></td>
<td><p>out</p></td>
<td><p>of</p></td>
<td><p>thread</p></td>
<td><p>18849600000.0</p></td>
</tr>
</tbody>
</table>
<p>To synchronize threads, you can use a mutex. This is useful in case you
need to sort out the printing, or, more importantly, to syncrhonize a
writing operation on some common variable. The following is a simple
example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;mutex&gt;</span>

<span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="w"> </span><span class="n">g_display_mutex</span><span class="p">;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">foo</span><span class="p">()</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="o">::</span><span class="n">id</span><span class="w"> </span><span class="n">this_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">get_id</span><span class="p">();</span>

<span class="w">    </span><span class="n">g_display_mutex</span><span class="p">.</span><span class="n">lock</span><span class="p">();</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;thread &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">this_id</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; sleeping...</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">g_display_mutex</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">t1</span><span class="p">(</span><span class="n">foo</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="w"> </span><span class="n">t2</span><span class="p">(</span><span class="n">foo</span><span class="p">);</span>

<span class="w">    </span><span class="n">t1</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="n">t2</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>thread</p></td>
<td><p>0x70000709a000</p></td>
<td><p>sleeping…</p></td>
</tr>
<tr class="row-odd"><td><p>thread</p></td>
<td><p>0x70000711d000</p></td>
<td><p>sleeping…</p></td>
</tr>
</tbody>
</table>
<p>Repeat several times. Although the thread id will change, the output
will not be mangled.</p>
<p>There is much more about threads, but since our focus will turn to
OpenMP, we will stop here. For more info check
<a class="reference external" href="https://en.cppreference.com/w/cpp/thread/thread">https://en.cppreference.com/w/cpp/thread/thread</a></p>
<section id="exercise">
<h3><span class="section-number">12.7.1. </span>Exercise<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h3>
<p>Fix the following code, which has a race condition, using a mutex (ref:
<a class="reference external" href="https://www.classes.cs.uchicago.edu/archive/2013/spring/12300-1/labs/lab6/">https://www.classes.cs.uchicago.edu/archive/2013/spring/12300-1/labs/lab6/</a>)
:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">square</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">result</span><span class="p">);</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="o">&gt;</span><span class="w"> </span><span class="n">ths</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">20</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">ths</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="p">(</span><span class="o">&amp;</span><span class="n">square</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">ref</span><span class="p">(</span><span class="n">accum</span><span class="p">)));</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">th</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">ths</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">th</span><span class="p">.</span><span class="n">join</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;accum = &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">accum</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">square</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">&amp;</span><span class="n">result</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2870</span>
</pre></div>
</div>
<p>The correct answer is <code class="docutils literal notranslate"><span class="pre">2870</span></code>, but if you repeat the execution many times
you will find different results. For instance, repeating the execution
1000 times and checking for the unique answers one gets</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span>i<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="o">{</span><span class="m">1</span>..1000<span class="o">}</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span>./a.out<span class="p">;</span><span class="w"> </span><span class="k">done</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>-c
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="m">2</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2509</span>
<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2674</span>
<span class="w">  </span><span class="m">2</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2749</span>
<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2806</span>
<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2834</span>
<span class="w">  </span><span class="m">4</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2845</span>
<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2854</span>
<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2861</span>
<span class="w">  </span><span class="m">2</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2866</span>
<span class="w">  </span><span class="m">6</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2869</span>
<span class="m">979</span><span class="w"> </span><span class="nv">accum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2870</span>
</pre></div>
</div>
<p>which shows that it not always yield 2870 .</p>
</section>
</section>
<section id="parallel-algorithms-in-c">
<h2><span class="section-number">12.8. </span>Parallel algorithms in c++<a class="headerlink" href="#parallel-algorithms-in-c" title="Link to this heading">#</a></h2>
<p>Since <code class="docutils literal notranslate"><span class="pre">c++17</span></code>, it is possible to execute some stl algorithms in parallel
(shared memory), without explictly using threads. See:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.cppreference.com/w/cpp/algorithm/execution_policy_tag_t">https://en.cppreference.com/w/cpp/algorithm/execution_policy_tag_t</a></p></li>
<li><p><a class="reference external" href="https://en.cppreference.com/w/cpp/algorithm">https://en.cppreference.com/w/cpp/algorithm</a></p></li>
<li><p><a class="reference external" href="https://en.cppreference.com/w/cpp/experimental/parallelism">https://en.cppreference.com/w/cpp/experimental/parallelism</a></p></li>
</ul>
<p>This a simple example for performing a sum</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;numeric&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="n">ARRAY_SIZE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100000000</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">myArray</span><span class="p">(</span><span class="n">ARRAY_SIZE</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">iota</span><span class="p">(</span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">// fill array with 0, 1, 2, ..., ARRAY_SIZE-1</span>

<span class="w">    </span><span class="c1">// sequential execution</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_seq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">accumulate</span><span class="p">(</span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mf">0.0</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Sequential sum: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">sum_seq</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// parallel execution</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_par</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par</span><span class="p">,</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Parallel sum: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">sum_par</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To compile, use</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-std<span class="o">=</span>c++17<span class="w"> </span>par.cpp<span class="w"> </span>-ltbb
</pre></div>
</div>
<p>This is linking with an intel threads implementation.</p>
<p>You can of course measure how much time is spent on each part. To do so,
we will use chrono:</p>
<ul class="simple">
<li><p>Implementation 1:</p></li>
</ul>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;numeric&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="n">ARRAY_SIZE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100000000</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">myArray</span><span class="p">(</span><span class="n">ARRAY_SIZE</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">iota</span><span class="p">(</span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">// fill array with 0, 1, 2, ..., ARRAY_SIZE-1</span>

<span class="w">    </span><span class="c1">// sequential execution</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">start_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_seq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">accumulate</span><span class="p">(</span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mf">0.0</span><span class="p">);</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">end_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">seq_duration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">milliseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end_time</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Sequential sum: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">sum_seq</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;( took : &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">seq_duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span><span class="o">/</span><span class="mf">1000.0</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; s)&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// parallel execution</span>
<span class="w">    </span><span class="n">start_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">sum_par</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par</span><span class="p">,</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="w">    </span><span class="n">end_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">    </span><span class="n">seq_duration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">milliseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end_time</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time</span><span class="p">);</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Parallel sum: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">sum_par</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;( took : &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">seq_duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span><span class="o">/</span><span class="mf">1000.0</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; s)&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Implementation 2:</p></li>
</ul>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;numeric&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;execution&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>

<span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">Func</span><span class="o">&gt;</span>
<span class="kt">void</span><span class="w"> </span><span class="n">time_function</span><span class="p">(</span><span class="n">Func</span><span class="w"> </span><span class="n">func</span><span class="p">);</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="n">ARRAY_SIZE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100000000</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">myArray</span><span class="p">(</span><span class="n">ARRAY_SIZE</span><span class="p">);</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">iota</span><span class="p">(</span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">// fill array with 0, 1, 2, ..., ARRAY_SIZE-1</span>

<span class="w">  </span><span class="c1">// sequential execution</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">serial</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="n">myArray</span><span class="p">](){</span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">accumulate</span><span class="p">(</span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mf">0.0</span><span class="p">);};</span>
<span class="w">  </span><span class="n">time_function</span><span class="p">(</span><span class="n">serial</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// parallel execution</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">parallel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="n">myArray</span><span class="p">](){</span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">reduce</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">par</span><span class="p">,</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">myArray</span><span class="p">.</span><span class="n">end</span><span class="p">());};</span>
<span class="w">  </span><span class="n">time_function</span><span class="p">(</span><span class="n">parallel</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">Func</span><span class="o">&gt;</span>
<span class="kt">void</span><span class="w"> </span><span class="n">time_function</span><span class="p">(</span><span class="n">Func</span><span class="w"> </span><span class="n">func</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">  </span><span class="n">func</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">duration_ms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">milliseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="p">).</span><span class="n">count</span><span class="p">();</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Elapsed time: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">duration_ms</span><span class="o">/</span><span class="mf">1000.0</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;  s&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The standard does not specify a way to control the nuber tof threads. If
you want to do so, and you are using Intel Threads Block implementation,
you can add gthe following header</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;tbb/task_scheduler_init.h&gt;</span>
</pre></div>
</div>
<p>and then , at some point, specify the thread total (in this case, 4)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">tbb</span><span class="o">::</span><span class="n">task_scheduler_init</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
<p>To learn more about the parallel algs, check</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.cppreference.com/w/cpp/algorithm">https://en.cppreference.com/w/cpp/algorithm</a></p></li>
</ul>
</section>
<section id="todo-gpu-programming-intro">
<h2><span class="section-number">12.9. </span><span class="todo TODO">TODO</span> Gpu Programming intro<a class="headerlink" href="#todo-gpu-programming-intro" title="Link to this heading">#</a></h2>
<section id="environment-setup-for-cuda">
<h3><span class="section-number">12.9.1. </span>Environment setup for cuda<a class="headerlink" href="#environment-setup-for-cuda" title="Link to this heading">#</a></h3>
<p>Here I show two ways to setup the dev environment. One is based on a
local computer with a graphics card, and the other using google collab.</p>
<ol class="arabic">
<li><p>Local environment</p>
<p>Here we will setup a computer which has an Nvidia Quadro P1000 card.
You need to install both the driver and the cuda toolkit (the later
better to be installed as a part of the nvidia sdk)</p>
<ul>
<li><p>Driver download for quadro P1000:
<a class="reference external" href="https://www.nvidia.com/Download/driverResults.aspx/204639/en-us/">https://www.nvidia.com/Download/driverResults.aspx/204639/en-us/</a></p></li>
<li><p>Nvidia sdk: <a class="reference external" href="https://developer.nvidia.com/hpc-sdk-downloads">https://developer.nvidia.com/hpc-sdk-downloads</a></p>
<ul>
<li><p>Nvidia singularity: This is the recommended way. The image
is built at
/packages/nvhpc<sub>23</sub>.3<sub>devel</sub>.sif. More
instructions at
<a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc">https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc</a></p>
<ol class="arabic">
<li><p>Accesing a shell inside the container but with
visibility to all user account files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>singularity<span class="w"> </span>shell<span class="w"> </span>--nv<span class="w"> </span>/packages/nvhpc_23.3_devel.sif
</pre></div>
</div>
</li>
<li><p>Compiling</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/packages/nvhpc_23.3_devel.sif<span class="w"> </span>nvc++<span class="w"> </span>-g<span class="w"> </span>cuda_02.cu
</pre></div>
</div>
</li>
<li><p>Executing with nvprof</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/packages/nvhpc_23.3_devel.sif<span class="w"> </span>nvprof<span class="w"> </span>./a.out
</pre></div>
</div>
</li>
</ol>
</li>
<li><p>Local module: Load the nvidia sdk (sala2):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>module<span class="w"> </span>load<span class="w"> </span>/packages/nvidia/hpc_sdk/modulefiles/nvhpc/23.3
</pre></div>
</div>
<p>Compile as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvc++<span class="w">  </span>-std<span class="o">=</span>c++17<span class="w"> </span>-o<span class="w"> </span>offload.x<span class="w"> </span>offload.cpp
</pre></div>
</div>
</li>
<li><p>The docker container is installed. Unfortunately it does not
run since the device compute capability is not enough</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>-it<span class="w"> </span>--rm<span class="w"> </span>nvcr.io/nvidia/nvhpc:23.3-devel-cuda_multi-ubuntu20.04
docker:<span class="w"> </span>Error<span class="w"> </span>response<span class="w"> </span>from<span class="w"> </span>daemon:<span class="w"> </span>could<span class="w"> </span>not<span class="w"> </span><span class="k">select</span><span class="w"> </span>device<span class="w"> </span>driver<span class="w"> </span><span class="s2">&quot;&quot;</span><span class="w"> </span>with<span class="w"> </span>capabilities:<span class="w"> </span><span class="o">[[</span>gpu<span class="o">]]</span>.
</pre></div>
</div>
<p>More info about container:
<a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc">https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc</a></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Google collab</p>
<p>Open a collab notebook, go to runtime, change runtime type, hardware
accelerator -&gt; GPU, GPU type -&gt; T4, Save. The you will have a
runtime with a T4 card, for free. If you want an even better card,
you can pay for collab pro.</p>
<p>Inside the notebook, you can run commands with the prefix <code class="docutils literal notranslate"><span class="pre">!</span></code> to run
then as in a console. For instance, to get the device properties,
you can run</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!nvidia-smi
</pre></div>
</div>
<p>to get something like</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">525</span>.85.12<span class="w">    </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">525</span>.85.12<span class="w">    </span>CUDA<span class="w"> </span>Version:<span class="w"> </span><span class="m">12</span>.0<span class="w">     </span><span class="p">|</span>
<span class="p">|</span>-------------------------------+----------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">        </span>Persistence-M<span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">        </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">  </span>Perf<span class="w">  </span>Pwr:Usage/Cap<span class="p">|</span><span class="w">         </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                               </span><span class="p">|</span><span class="w">                      </span><span class="p">|</span><span class="w">               </span>MIG<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>Tesla<span class="w"> </span>T4<span class="w">            </span>Off<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">00000000</span>:00:04.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                    </span><span class="m">0</span><span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>N/A<span class="w">   </span>44C<span class="w">    </span>P8<span class="w">     </span>9W<span class="w"> </span>/<span class="w">  </span>70W<span class="w"> </span><span class="p">|</span><span class="w">      </span>0MiB<span class="w"> </span>/<span class="w"> </span>15360MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                               </span><span class="p">|</span><span class="w">                      </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>Processes:<span class="w">                                                                  </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>GPU<span class="w">   </span>GI<span class="w">   </span>CI<span class="w">        </span>PID<span class="w">   </span>Type<span class="w">   </span>Process<span class="w"> </span>name<span class="w">                  </span>GPU<span class="w"> </span>Memory<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">        </span>ID<span class="w">   </span>ID<span class="w">                                                   </span>Usage<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="o">=============================================================================</span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span>No<span class="w"> </span>running<span class="w"> </span>processes<span class="w"> </span>found<span class="w">                                                 </span><span class="p">|</span>
+-----------------------------------------------------------------------------+
</pre></div>
</div>
<p>To create local files, like <code class="docutils literal notranslate"><span class="pre">filename.cu</span></code>, use the magic
<code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">filename.cu</span></code> at the beginning of the cell and then put the file
contents in the same cell.</p>
<p>Finally, to compile and run just execute the following</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!nvcc<span class="w"> </span>filename.cu<span class="w"> </span>-o<span class="w"> </span>name.x
!nvprof<span class="w"> </span>./name.x
</pre></div>
</div>
</li>
</ol>
</section>
<section id="todo-cuda-intro">
<h3><span class="section-number">12.9.2. </span><span class="todo TODO">TODO</span> Cuda intro<a class="headerlink" href="#todo-cuda-intro" title="Link to this heading">#</a></h3>
<p>REF <a class="reference external" href="https://en.wikipedia.org/wiki/CUDA?useskin=vector">https://en.wikipedia.org/wiki/CUDA?useskin=vector</a> Tutorial1:
<a class="reference external" href="https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/">https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/</a>
Tutorial2
<a class="reference external" href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">https://developer.nvidia.com/blog/even-easier-introduction-cuda/</a></p>
<ol class="arabic">
<li><p>Tutorial 1</p>
<p><a class="reference external" href="https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/">https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/</a>
Example in c</p>
<p>Compile as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>gcc<span class="w"> </span>example_01.c
</pre></div>
</div>
<p>Now the same but in cuda:</p>
<p>Compile as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvcc<span class="w"> </span>example_01.cu
</pre></div>
</div>
<p>Execution will show errors, due to the fact that the code is NOT
running on the device.</p>
<p>We need to allocate memory on it(<code class="docutils literal notranslate"><span class="pre">cudaMalloc</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaFree</span></code>), and
trasfer data to and from it (<code class="docutils literal notranslate"><span class="pre">cudaMemCopy</span></code>).</p>
</li>
<li><p>Tutorial 2</p>
<p><a class="reference external" href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">https://developer.nvidia.com/blog/even-easier-introduction-cuda/</a></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>

<span class="c1">// function to add the elements of two arrays</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span><span class="w"> </span><span class="c1">// 1M elements</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">float</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">float</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>

<span class="w">  </span><span class="c1">// initialize x and y arrays on the host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run kernel on 1M elements on the CPU</span>
<span class="w">  </span><span class="n">add</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Check for errors (all values should be 3.0f)</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmax</span><span class="p">(</span><span class="n">maxError</span><span class="p">,</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="mf">-3.0f</span><span class="p">));</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Max error: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free memory</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">[]</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">[]</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>g++<span class="w"> </span>-g<span class="w"> </span>-std<span class="o">=</span>c++17<span class="w"> </span>cuda_01.cpp
</pre></div>
</div>
<p>Cuda example</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>
<span class="c1">// Kernel function to add the elements of two arrays</span>
<span class="kr">__global__</span>
<span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate Unified Memory – accessible from CPU or GPU</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// initialize x and y arrays on the host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run kernel on 1M elements on the GPU</span>
<span class="w">  </span><span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Wait for GPU to finish before accessing on host</span>
<span class="w">  </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Check for errors (all values should be 3.0f)</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmax</span><span class="p">(</span><span class="n">maxError</span><span class="p">,</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="mf">-3.0f</span><span class="p">));</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Max error: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free memory</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To compile, use <code class="docutils literal notranslate"><span class="pre">nvc++</span></code>.</p>
<p>If you have a singularity container with the nvidia sdk, you can
just run the following</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/packages/nvhpc_23.3_devel.sif<span class="w"> </span>nvc++<span class="w"> </span>-g<span class="w"> </span>cuda_02.cu
singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/packages/nvhpc_23.3_devel.sif<span class="w"> </span>./a.out
singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/packages/nvhpc_23.3_devel.sif<span class="w"> </span>nvprof<span class="w"> </span>./a.out
</pre></div>
</div>
<p>and get something like</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="nv">16094</span><span class="o">==</span><span class="w"> </span>NVPROF<span class="w"> </span>is<span class="w"> </span>profiling<span class="w"> </span>process<span class="w"> </span><span class="m">16094</span>,<span class="w"> </span>command:<span class="w"> </span>./a.out
Max<span class="w"> </span>error:<span class="w"> </span><span class="nv">0</span>
<span class="o">==</span><span class="nv">16094</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>application:<span class="w"> </span>./a.out
<span class="o">==</span><span class="nv">16094</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>result:
<span class="w">            </span>Type<span class="w">  </span>Time<span class="o">(</span>%<span class="o">)</span><span class="w">      </span>Time<span class="w">     </span>Calls<span class="w">       </span>Avg<span class="w">       </span>Min<span class="w">       </span>Max<span class="w">  </span>Name
<span class="w"> </span>GPU<span class="w"> </span>activities:<span class="w">  </span><span class="m">100</span>.00%<span class="w">  </span><span class="m">2</span>.54774s<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">2</span>.54774s<span class="w">  </span><span class="m">2</span>.54774s<span class="w">  </span><span class="m">2</span>.54774s<span class="w">  </span>add<span class="o">(</span>int,<span class="w"> </span>float*,<span class="w"> </span>float*<span class="o">)</span>
<span class="w">      </span>API<span class="w"> </span>calls:<span class="w">   </span><span class="m">93</span>.27%<span class="w">  </span><span class="m">2</span>.54776s<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">2</span>.54776s<span class="w">  </span><span class="m">2</span>.54776s<span class="w">  </span><span class="m">2</span>.54776s<span class="w">  </span>cudaDeviceSynchronize
<span class="w">                    </span><span class="m">6</span>.71%<span class="w">  </span><span class="m">183</span>.20ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">91</span>.602ms<span class="w">  </span><span class="m">20</span>.540us<span class="w">  </span><span class="m">183</span>.18ms<span class="w">  </span>cudaMallocManaged
<span class="w">                    </span><span class="m">0</span>.02%<span class="w">  </span><span class="m">468</span>.25us<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">234</span>.13us<span class="w">  </span><span class="m">216</span>.27us<span class="w">  </span><span class="m">251</span>.98us<span class="w">  </span>cudaFree
<span class="w">                    </span><span class="m">0</span>.01%<span class="w">  </span><span class="m">213</span>.75us<span class="w">       </span><span class="m">101</span><span class="w">  </span><span class="m">2</span>.1160us<span class="w">     </span>141ns<span class="w">  </span><span class="m">150</span>.11us<span class="w">  </span>cuDeviceGetAttribute
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">32</span>.127us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">32</span>.127us<span class="w">  </span><span class="m">32</span>.127us<span class="w">  </span><span class="m">32</span>.127us<span class="w">  </span>cudaLaunchKernel
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">22</span>.239us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">22</span>.239us<span class="w">  </span><span class="m">22</span>.239us<span class="w">  </span><span class="m">22</span>.239us<span class="w">  </span>cuDeviceGetName
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">6</span>.1330us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">6</span>.1330us<span class="w">  </span><span class="m">6</span>.1330us<span class="w">  </span><span class="m">6</span>.1330us<span class="w">  </span>cuDeviceGetPCIBusId
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">1</span>.5730us<span class="w">         </span><span class="m">3</span><span class="w">     </span>524ns<span class="w">     </span>197ns<span class="w">  </span><span class="m">1</span>.1650us<span class="w">  </span>cuDeviceGetCount
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>808ns<span class="w">         </span><span class="m">2</span><span class="w">     </span>404ns<span class="w">     </span>141ns<span class="w">     </span>667ns<span class="w">  </span>cuDeviceGet
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>530ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>530ns<span class="w">     </span>530ns<span class="w">     </span>530ns<span class="w">  </span>cuDeviceTotalMem
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>243ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>243ns<span class="w">     </span>243ns<span class="w">     </span>243ns<span class="w">  </span><span class="nv">cuDeviceGetUuid</span>

<span class="o">==</span><span class="nv">16094</span><span class="o">==</span><span class="w"> </span>Unified<span class="w"> </span>Memory<span class="w"> </span>profiling<span class="w"> </span>result:
Device<span class="w"> </span><span class="s2">&quot;Quadro P1000 (0)&quot;</span>
<span class="w">   </span>Count<span class="w">  </span>Avg<span class="w"> </span>Size<span class="w">  </span>Min<span class="w"> </span>Size<span class="w">  </span>Max<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Time<span class="w">  </span>Name
<span class="w">      </span><span class="m">48</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">8</span>.000000MB<span class="w">  </span><span class="m">735</span>.2380us<span class="w">  </span>Host<span class="w"> </span>To<span class="w"> </span>Device
<span class="w">      </span><span class="m">24</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">4</span>.000000MB<span class="w">  </span><span class="m">337</span>.3770us<span class="w">  </span>Device<span class="w"> </span>To<span class="w"> </span>Host
<span class="w">      </span><span class="m">24</span><span class="w">         </span>-<span class="w">         </span>-<span class="w">         </span>-<span class="w">           </span>-<span class="w">  </span><span class="m">2</span>.855987ms<span class="w">  </span>Gpu<span class="w"> </span>page<span class="w"> </span>fault<span class="w"> </span>groups
Total<span class="w"> </span>CPU<span class="w"> </span>Page<span class="w"> </span>faults:<span class="w"> </span><span class="m">36</span>
</pre></div>
</div>
<p>You can also run it on google collab, where you will have an nvidia
T4 card available for free (after changing the runtime), with the
following typical output</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="nv">18853</span><span class="o">==</span><span class="w"> </span>NVPROF<span class="w"> </span>is<span class="w"> </span>profiling<span class="w"> </span>process<span class="w"> </span><span class="m">18853</span>,<span class="w"> </span>command:<span class="w"> </span>./cuda_02.x
Max<span class="w"> </span>error:<span class="w"> </span><span class="nv">0</span>
<span class="o">==</span><span class="nv">18853</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>application:<span class="w"> </span>./cuda_02.x
<span class="o">==</span><span class="nv">18853</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>result:
<span class="w">            </span>Type<span class="w">  </span>Time<span class="o">(</span>%<span class="o">)</span><span class="w">      </span>Time<span class="w">     </span>Calls<span class="w">       </span>Avg<span class="w">       </span>Min<span class="w">       </span>Max<span class="w">  </span>Name
<span class="w"> </span>GPU<span class="w"> </span>activities:<span class="w">  </span><span class="m">100</span>.00%<span class="w">  </span><span class="m">108</span>.83ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">108</span>.83ms<span class="w">  </span><span class="m">108</span>.83ms<span class="w">  </span><span class="m">108</span>.83ms<span class="w">  </span>add<span class="o">(</span>int,<span class="w"> </span>float*,<span class="w"> </span>float*<span class="o">)</span>
<span class="w">      </span>API<span class="w"> </span>calls:<span class="w">   </span><span class="m">72</span>.48%<span class="w">  </span><span class="m">290</span>.34ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">145</span>.17ms<span class="w">  </span><span class="m">36</span>.191us<span class="w">  </span><span class="m">290</span>.31ms<span class="w">  </span>cudaMallocManaged
<span class="w">                   </span><span class="m">27</span>.17%<span class="w">  </span><span class="m">108</span>.84ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">108</span>.84ms<span class="w">  </span><span class="m">108</span>.84ms<span class="w">  </span><span class="m">108</span>.84ms<span class="w">  </span>cudaDeviceSynchronize
<span class="w">                    </span><span class="m">0</span>.28%<span class="w">  </span><span class="m">1</span>.1298ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">564</span>.90us<span class="w">  </span><span class="m">537</span>.96us<span class="w">  </span><span class="m">591</span>.84us<span class="w">  </span>cudaFree
<span class="w">                    </span><span class="m">0</span>.05%<span class="w">  </span><span class="m">182</span>.13us<span class="w">       </span><span class="m">101</span><span class="w">  </span><span class="m">1</span>.8030us<span class="w">     </span>264ns<span class="w">  </span><span class="m">75</span>.268us<span class="w">  </span>cuDeviceGetAttribute
<span class="w">                    </span><span class="m">0</span>.01%<span class="w">  </span><span class="m">48</span>.553us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">48</span>.553us<span class="w">  </span><span class="m">48</span>.553us<span class="w">  </span><span class="m">48</span>.553us<span class="w">  </span>cudaLaunchKernel
<span class="w">                    </span><span class="m">0</span>.01%<span class="w">  </span><span class="m">28</span>.488us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">28</span>.488us<span class="w">  </span><span class="m">28</span>.488us<span class="w">  </span><span class="m">28</span>.488us<span class="w">  </span>cuDeviceGetName
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">8</span>.6520us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">8</span>.6520us<span class="w">  </span><span class="m">8</span>.6520us<span class="w">  </span><span class="m">8</span>.6520us<span class="w">  </span>cuDeviceGetPCIBusId
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">2</span>.3140us<span class="w">         </span><span class="m">3</span><span class="w">     </span>771ns<span class="w">     </span>328ns<span class="w">  </span><span class="m">1</span>.6230us<span class="w">  </span>cuDeviceGetCount
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>919ns<span class="w">         </span><span class="m">2</span><span class="w">     </span>459ns<span class="w">     </span>315ns<span class="w">     </span>604ns<span class="w">  </span>cuDeviceGet
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>580ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>580ns<span class="w">     </span>580ns<span class="w">     </span>580ns<span class="w">  </span>cuDeviceTotalMem
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>532ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>532ns<span class="w">     </span>532ns<span class="w">     </span>532ns<span class="w">  </span>cuModuleGetLoadingMode
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>382ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>382ns<span class="w">     </span>382ns<span class="w">     </span>382ns<span class="w">  </span><span class="nv">cuDeviceGetUuid</span>

<span class="o">==</span><span class="nv">18853</span><span class="o">==</span><span class="w"> </span>Unified<span class="w"> </span>Memory<span class="w"> </span>profiling<span class="w"> </span>result:
Device<span class="w"> </span><span class="s2">&quot;Tesla T4 (0)&quot;</span>
<span class="w">   </span>Count<span class="w">  </span>Avg<span class="w"> </span>Size<span class="w">  </span>Min<span class="w"> </span>Size<span class="w">  </span>Max<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Time<span class="w">  </span>Name
<span class="w">      </span><span class="m">48</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">8</span>.000000MB<span class="w">  </span><span class="m">809</span>.9640us<span class="w">  </span>Host<span class="w"> </span>To<span class="w"> </span>Device
<span class="w">      </span><span class="m">24</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">4</span>.000000MB<span class="w">  </span><span class="m">360</span>.6320us<span class="w">  </span>Device<span class="w"> </span>To<span class="w"> </span>Host
<span class="w">      </span><span class="m">12</span><span class="w">         </span>-<span class="w">         </span>-<span class="w">         </span>-<span class="w">           </span>-<span class="w">  </span><span class="m">2</span>.564287ms<span class="w">  </span>Gpu<span class="w"> </span>page<span class="w"> </span>fault<span class="w"> </span>groups
Total<span class="w"> </span>CPU<span class="w"> </span>Page<span class="w"> </span>faults:<span class="w"> </span><span class="m">36</span>
</pre></div>
</div>
<p>If you increase just the number of threads to 256 (check the change
in <code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;...&gt;&gt;&gt;</span></code>), and split correctly the work using the cuda vars
<code class="docutils literal notranslate"><span class="pre">threadIdx.x</span></code> (thread id in the block) and <code class="docutils literal notranslate"><span class="pre">blockDim.x</span></code> (number of
threads in the block), as shown,</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span>
<span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">index</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span>
<span class="w">      </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Run kernel on 1M elements on the GPU</span>
<span class="w">  </span><span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
<p>then you get the following output</p>
<ul>
<li><p>Quadro P1000 : From 2.5 secs to 0.022 secs!</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="nv">21739</span><span class="o">==</span><span class="w"> </span>NVPROF<span class="w"> </span>is<span class="w"> </span>profiling<span class="w"> </span>process<span class="w"> </span><span class="m">21739</span>,<span class="w"> </span>command:<span class="w"> </span>./a.out
Max<span class="w"> </span>error:<span class="w"> </span><span class="nv">0</span>
<span class="o">==</span><span class="nv">21739</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>application:<span class="w"> </span>./a.out
<span class="o">==</span><span class="nv">21739</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>result:
<span class="w">            </span>Type<span class="w">  </span>Time<span class="o">(</span>%<span class="o">)</span><span class="w">      </span>Time<span class="w">     </span>Calls<span class="w">       </span>Avg<span class="w">       </span>Min<span class="w">       </span>Max<span class="w">  </span>Name
<span class="w"> </span>GPU<span class="w"> </span>activities:<span class="w">  </span><span class="m">100</span>.00%<span class="w">  </span><span class="m">21</span>.978ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">21</span>.978ms<span class="w">  </span><span class="m">21</span>.978ms<span class="w">  </span><span class="m">21</span>.978ms<span class="w">  </span>add<span class="o">(</span>int,<span class="w"> </span>float*,<span class="w"> </span>float*<span class="o">)</span>
<span class="w">      </span>API<span class="w"> </span>calls:<span class="w">   </span><span class="m">87</span>.86%<span class="w">  </span><span class="m">164</span>.24ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">82</span>.118ms<span class="w">  </span><span class="m">12</span>.398us<span class="w">  </span><span class="m">164</span>.22ms<span class="w">  </span>cudaMallocManaged
<span class="w">                   </span><span class="m">11</span>.76%<span class="w">  </span><span class="m">21</span>.980ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">21</span>.980ms<span class="w">  </span><span class="m">21</span>.980ms<span class="w">  </span><span class="m">21</span>.980ms<span class="w">  </span>cudaDeviceSynchronize
<span class="w">                    </span><span class="m">0</span>.24%<span class="w">  </span><span class="m">457</span>.32us<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">228</span>.66us<span class="w">  </span><span class="m">177</span>.89us<span class="w">  </span><span class="m">279</span>.43us<span class="w">  </span>cudaFree
<span class="w">                    </span><span class="m">0</span>.11%<span class="w">  </span><span class="m">206</span>.80us<span class="w">       </span><span class="m">101</span><span class="w">  </span><span class="m">2</span>.0470us<span class="w">     </span>128ns<span class="w">  </span><span class="m">144</span>.81us<span class="w">  </span>cuDeviceGetAttribute
<span class="w">                    </span><span class="m">0</span>.02%<span class="w">  </span><span class="m">29</span>.041us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">29</span>.041us<span class="w">  </span><span class="m">29</span>.041us<span class="w">  </span><span class="m">29</span>.041us<span class="w">  </span>cudaLaunchKernel
<span class="w">                    </span><span class="m">0</span>.01%<span class="w">  </span><span class="m">20</span>.149us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">20</span>.149us<span class="w">  </span><span class="m">20</span>.149us<span class="w">  </span><span class="m">20</span>.149us<span class="w">  </span>cuDeviceGetName
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">5</span>.5860us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">5</span>.5860us<span class="w">  </span><span class="m">5</span>.5860us<span class="w">  </span><span class="m">5</span>.5860us<span class="w">  </span>cuDeviceGetPCIBusId
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">2</span>.1000us<span class="w">         </span><span class="m">3</span><span class="w">     </span>700ns<span class="w">     </span>277ns<span class="w">     </span>958ns<span class="w">  </span>cuDeviceGetCount
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>952ns<span class="w">         </span><span class="m">2</span><span class="w">     </span>476ns<span class="w">     </span>330ns<span class="w">     </span>622ns<span class="w">  </span>cuDeviceGet
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>391ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>391ns<span class="w">     </span>391ns<span class="w">     </span>391ns<span class="w">  </span>cuDeviceTotalMem
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>259ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>259ns<span class="w">     </span>259ns<span class="w">     </span>259ns<span class="w">  </span><span class="nv">cuDeviceGetUuid</span>

<span class="o">==</span><span class="nv">21739</span><span class="o">==</span><span class="w"> </span>Unified<span class="w"> </span>Memory<span class="w"> </span>profiling<span class="w"> </span>result:
Device<span class="w"> </span><span class="s2">&quot;Quadro P1000 (0)&quot;</span>
<span class="w">   </span>Count<span class="w">  </span>Avg<span class="w"> </span>Size<span class="w">  </span>Min<span class="w"> </span>Size<span class="w">  </span>Max<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Time<span class="w">  </span>Name
<span class="w">      </span><span class="m">48</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">8</span>.000000MB<span class="w">  </span><span class="m">734</span>.5940us<span class="w">  </span>Host<span class="w"> </span>To<span class="w"> </span>Device
<span class="w">      </span><span class="m">24</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">4</span>.000000MB<span class="w">  </span><span class="m">338</span>.5950us<span class="w">  </span>Device<span class="w"> </span>To<span class="w"> </span>Host
<span class="w">      </span><span class="m">24</span><span class="w">         </span>-<span class="w">         </span>-<span class="w">         </span>-<span class="w">           </span>-<span class="w">  </span><span class="m">1</span>.764587ms<span class="w">  </span>Gpu<span class="w"> </span>page<span class="w"> </span>fault<span class="w"> </span>groups
Total<span class="w"> </span>CPU<span class="w"> </span>Page<span class="w"> </span>faults:<span class="w"> </span><span class="m">36</span>
</pre></div>
</div>
</li>
<li><p>Tesla T4: From 0.108 secs to 0.004 secs!</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="nv">21448</span><span class="o">==</span><span class="w"> </span>NVPROF<span class="w"> </span>is<span class="w"> </span>profiling<span class="w"> </span>process<span class="w"> </span><span class="m">21448</span>,<span class="w"> </span>command:<span class="w"> </span>./cuda_03.x
Max<span class="w"> </span>error:<span class="w"> </span><span class="nv">0</span>
<span class="o">==</span><span class="nv">21448</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>application:<span class="w"> </span>./cuda_03.x
<span class="o">==</span><span class="nv">21448</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>result:
<span class="w">            </span>Type<span class="w">  </span>Time<span class="o">(</span>%<span class="o">)</span><span class="w">      </span>Time<span class="w">     </span>Calls<span class="w">       </span>Avg<span class="w">       </span>Min<span class="w">       </span>Max<span class="w">  </span>Name
<span class="w"> </span>GPU<span class="w"> </span>activities:<span class="w">  </span><span class="m">100</span>.00%<span class="w">  </span><span class="m">3</span>.7978ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">3</span>.7978ms<span class="w">  </span><span class="m">3</span>.7978ms<span class="w">  </span><span class="m">3</span>.7978ms<span class="w">  </span>add<span class="o">(</span>int,<span class="w"> </span>float*,<span class="w"> </span>float*<span class="o">)</span>
<span class="w">      </span>API<span class="w"> </span>calls:<span class="w">   </span><span class="m">98</span>.24%<span class="w">  </span><span class="m">291</span>.22ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">145</span>.61ms<span class="w">  </span><span class="m">73</span>.005us<span class="w">  </span><span class="m">291</span>.15ms<span class="w">  </span>cudaMallocManaged
<span class="w">                    </span><span class="m">1</span>.28%<span class="w">  </span><span class="m">3</span>.8044ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">3</span>.8044ms<span class="w">  </span><span class="m">3</span>.8044ms<span class="w">  </span><span class="m">3</span>.8044ms<span class="w">  </span>cudaDeviceSynchronize
<span class="w">                    </span><span class="m">0</span>.36%<span class="w">  </span><span class="m">1</span>.0699ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">534</span>.95us<span class="w">  </span><span class="m">512</span>.29us<span class="w">  </span><span class="m">557</span>.62us<span class="w">  </span>cudaFree
<span class="w">                    </span><span class="m">0</span>.08%<span class="w">  </span><span class="m">222</span>.64us<span class="w">       </span><span class="m">101</span><span class="w">  </span><span class="m">2</span>.2040us<span class="w">     </span>174ns<span class="w">  </span><span class="m">102</span>.62us<span class="w">  </span>cuDeviceGetAttribute
<span class="w">                    </span><span class="m">0</span>.02%<span class="w">  </span><span class="m">62</span>.588us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">62</span>.588us<span class="w">  </span><span class="m">62</span>.588us<span class="w">  </span><span class="m">62</span>.588us<span class="w">  </span>cudaLaunchKernel
<span class="w">                    </span><span class="m">0</span>.02%<span class="w">  </span><span class="m">44</span>.725us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">44</span>.725us<span class="w">  </span><span class="m">44</span>.725us<span class="w">  </span><span class="m">44</span>.725us<span class="w">  </span>cuDeviceGetName
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">8</span>.1290us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">8</span>.1290us<span class="w">  </span><span class="m">8</span>.1290us<span class="w">  </span><span class="m">8</span>.1290us<span class="w">  </span>cuDeviceGetPCIBusId
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">3</span>.2970us<span class="w">         </span><span class="m">3</span><span class="w">  </span><span class="m">1</span>.0990us<span class="w">     </span>266ns<span class="w">  </span><span class="m">2</span>.6840us<span class="w">  </span>cuDeviceGetCount
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">1</span>.7320us<span class="w">         </span><span class="m">2</span><span class="w">     </span>866ns<span class="w">     </span>352ns<span class="w">  </span><span class="m">1</span>.3800us<span class="w">  </span>cuDeviceGet
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>632ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>632ns<span class="w">     </span>632ns<span class="w">     </span>632ns<span class="w">  </span>cuDeviceTotalMem
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>549ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>549ns<span class="w">     </span>549ns<span class="w">     </span>549ns<span class="w">  </span>cuModuleGetLoadingMode
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>377ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>377ns<span class="w">     </span>377ns<span class="w">     </span>377ns<span class="w">  </span><span class="nv">cuDeviceGetUuid</span>

<span class="o">==</span><span class="nv">21448</span><span class="o">==</span><span class="w"> </span>Unified<span class="w"> </span>Memory<span class="w"> </span>profiling<span class="w"> </span>result:
Device<span class="w"> </span><span class="s2">&quot;Tesla T4 (0)&quot;</span>
<span class="w">   </span>Count<span class="w">  </span>Avg<span class="w"> </span>Size<span class="w">  </span>Min<span class="w"> </span>Size<span class="w">  </span>Max<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Time<span class="w">  </span>Name
<span class="w">      </span><span class="m">48</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">8</span>.000000MB<span class="w">  </span><span class="m">825</span>.8720us<span class="w">  </span>Host<span class="w"> </span>To<span class="w"> </span>Device
<span class="w">      </span><span class="m">24</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">4</span>.000000MB<span class="w">  </span><span class="m">360</span>.3130us<span class="w">  </span>Device<span class="w"> </span>To<span class="w"> </span>Host
<span class="w">      </span><span class="m">13</span><span class="w">         </span>-<span class="w">         </span>-<span class="w">         </span>-<span class="w">           </span>-<span class="w">  </span><span class="m">2</span>.951606ms<span class="w">  </span>Gpu<span class="w"> </span>page<span class="w"> </span>fault<span class="w"> </span>groups
Total<span class="w"> </span>CPU<span class="w"> </span>Page<span class="w"> </span>faults:<span class="w"> </span><span class="m">36</span>
</pre></div>
</div>
</li>
</ul>
<p>Cuda devices group parallel processors into Streaming
Multiprocessors (SM), and each of them can run several threads in
parallel. In our case, by using the command <code class="docutils literal notranslate"><span class="pre">deviceQuery</span></code> (for the
QuadroP1000 system it is at
<code class="docutils literal notranslate"><span class="pre">/opt/cuda/extras/demo_suite/deviceQuery</span></code>), we get</p>
<ul class="simple">
<li><p>Quadro P1000: 5 SM, 128 threads/SM</p></li>
<li><p>Tesla T4: 32 SM, 128 threads/SM</p></li>
</ul>
<p>So the ideal number of threads changes per card, and we will compute
as</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">blockSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">128</span><span class="p">;</span>
<span class="kt">int</span><span class="w"> </span><span class="n">numBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockSize</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">blockSize</span><span class="p">;</span><span class="w"> </span><span class="c1">// what if N is not divisible by blocksize?</span>
<span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="n">numBlocks</span><span class="p">,</span><span class="w"> </span><span class="n">blockSize</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
<p>Notice that you can also compute this constant by using the follow
code (generated by bard.google.com)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Get the number of threads per multiprocessor.</span>
<span class="kt">int</span><span class="w"> </span><span class="n">threadsPerMultiprocessor</span><span class="p">;</span>
<span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaDeviceGetAttribute</span><span class="p">(</span><span class="o">&amp;</span><span class="n">threadsPerMultiprocessor</span><span class="p">,</span><span class="w"> </span><span class="n">cudaDevAttrMaxThreadsPerMultiprocessor</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Handle error.</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The kernel will now become</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span>
<span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">index</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
<p>based on the job distribution done by the tutorial
<a class="reference external" href="https://developer-blogs.nvidia.com/wp-content/uploads/2017/01/cuda_indexing.png">https://developer-blogs.nvidia.com/wp-content/uploads/2017/01/cuda_indexing.png</a></p>
<p>Now we get</p>
<ul>
<li><p>Nvidia Quadro P1000: From 2.500 to 0.022 to 0.006 secs!</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="nv">10662</span><span class="o">==</span><span class="w"> </span>NVPROF<span class="w"> </span>is<span class="w"> </span>profiling<span class="w"> </span>process<span class="w"> </span><span class="m">10662</span>,<span class="w"> </span>command:<span class="w"> </span>./a.out
Max<span class="w"> </span>error:<span class="w"> </span><span class="nv">0</span>
<span class="o">==</span><span class="nv">10662</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>application:<span class="w"> </span>./a.out
<span class="o">==</span><span class="nv">10662</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>result:
<span class="w">            </span>Type<span class="w">  </span>Time<span class="o">(</span>%<span class="o">)</span><span class="w">      </span>Time<span class="w">     </span>Calls<span class="w">       </span>Avg<span class="w">       </span>Min<span class="w">       </span>Max<span class="w">  </span>Name
<span class="w"> </span>GPU<span class="w"> </span>activities:<span class="w">  </span><span class="m">100</span>.00%<span class="w">  </span><span class="m">6</span>.0868ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">6</span>.0868ms<span class="w">  </span><span class="m">6</span>.0868ms<span class="w">  </span><span class="m">6</span>.0868ms<span class="w">  </span>add<span class="o">(</span>int,<span class="w"> </span>float*,<span class="w"> </span>float*<span class="o">)</span>
<span class="w">      </span>API<span class="w"> </span>calls:<span class="w">   </span><span class="m">96</span>.03%<span class="w">  </span><span class="m">165</span>.28ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">82</span>.641ms<span class="w">  </span><span class="m">13</span>.911us<span class="w">  </span><span class="m">165</span>.27ms<span class="w">  </span>cudaMallocManaged
<span class="w">                    </span><span class="m">3</span>.54%<span class="w">  </span><span class="m">6</span>.0887ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">6</span>.0887ms<span class="w">  </span><span class="m">6</span>.0887ms<span class="w">  </span><span class="m">6</span>.0887ms<span class="w">  </span>cudaDeviceSynchronize
<span class="w">                    </span><span class="m">0</span>.27%<span class="w">  </span><span class="m">460</span>.56us<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">230</span>.28us<span class="w">  </span><span class="m">184</span>.71us<span class="w">  </span><span class="m">275</span>.85us<span class="w">  </span>cudaFree
<span class="w">                    </span><span class="m">0</span>.13%<span class="w">  </span><span class="m">215</span>.37us<span class="w">       </span><span class="m">101</span><span class="w">  </span><span class="m">2</span>.1320us<span class="w">     </span>133ns<span class="w">  </span><span class="m">151</span>.55us<span class="w">  </span>cuDeviceGetAttribute
<span class="w">                    </span><span class="m">0</span>.02%<span class="w">  </span><span class="m">30</span>.822us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">30</span>.822us<span class="w">  </span><span class="m">30</span>.822us<span class="w">  </span><span class="m">30</span>.822us<span class="w">  </span>cudaLaunchKernel
<span class="w">                    </span><span class="m">0</span>.01%<span class="w">  </span><span class="m">22</span>.122us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">22</span>.122us<span class="w">  </span><span class="m">22</span>.122us<span class="w">  </span><span class="m">22</span>.122us<span class="w">  </span>cuDeviceGetName
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">5</span>.7430us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">5</span>.7430us<span class="w">  </span><span class="m">5</span>.7430us<span class="w">  </span><span class="m">5</span>.7430us<span class="w">  </span>cuDeviceGetPCIBusId
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">1</span>.3810us<span class="w">         </span><span class="m">3</span><span class="w">     </span>460ns<span class="w">     </span>203ns<span class="w">     </span>945ns<span class="w">  </span>cuDeviceGetCount
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>921ns<span class="w">         </span><span class="m">2</span><span class="w">     </span>460ns<span class="w">     </span>163ns<span class="w">     </span>758ns<span class="w">  </span>cuDeviceGet
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>438ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>438ns<span class="w">     </span>438ns<span class="w">     </span>438ns<span class="w">  </span>cuDeviceTotalMem
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>234ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>234ns<span class="w">     </span>234ns<span class="w">     </span>234ns<span class="w">  </span><span class="nv">cuDeviceGetUuid</span>

<span class="o">==</span><span class="nv">10662</span><span class="o">==</span><span class="w"> </span>Unified<span class="w"> </span>Memory<span class="w"> </span>profiling<span class="w"> </span>result:
Device<span class="w"> </span><span class="s2">&quot;Quadro P1000 (0)&quot;</span>
<span class="w">   </span>Count<span class="w">  </span>Avg<span class="w"> </span>Size<span class="w">  </span>Min<span class="w"> </span>Size<span class="w">  </span>Max<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Time<span class="w">  </span>Name
<span class="w">      </span><span class="m">59</span><span class="w">  </span><span class="m">138</span>.85KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">8</span>.000000MB<span class="w">  </span><span class="m">740</span>.3880us<span class="w">  </span>Host<span class="w"> </span>To<span class="w"> </span>Device
<span class="w">      </span><span class="m">24</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">4</span>.000000MB<span class="w">  </span><span class="m">337</span>.8280us<span class="w">  </span>Device<span class="w"> </span>To<span class="w"> </span>Host
<span class="w">      </span><span class="m">32</span><span class="w">         </span>-<span class="w">         </span>-<span class="w">         </span>-<span class="w">           </span>-<span class="w">  </span><span class="m">2</span>.253582ms<span class="w">  </span>Gpu<span class="w"> </span>page<span class="w"> </span>fault<span class="w"> </span>groups
Total<span class="w"> </span>CPU<span class="w"> </span>Page<span class="w"> </span>faults:<span class="w"> </span><span class="m">36</span>
</pre></div>
</div>
</li>
<li><p>Testla T4: From 0.108 to 0.004 to 0.003 secs</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">==</span><span class="nv">8972</span><span class="o">==</span><span class="w"> </span>NVPROF<span class="w"> </span>is<span class="w"> </span>profiling<span class="w"> </span>process<span class="w"> </span><span class="m">8972</span>,<span class="w"> </span>command:<span class="w"> </span>./cuda_04.x
Max<span class="w"> </span>error:<span class="w"> </span><span class="nv">0</span>
<span class="o">==</span><span class="nv">8972</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>application:<span class="w"> </span>./cuda_04.x
<span class="o">==</span><span class="nv">8972</span><span class="o">==</span><span class="w"> </span>Profiling<span class="w"> </span>result:
<span class="w">            </span>Type<span class="w">  </span>Time<span class="o">(</span>%<span class="o">)</span><span class="w">      </span>Time<span class="w">     </span>Calls<span class="w">       </span>Avg<span class="w">       </span>Min<span class="w">       </span>Max<span class="w">  </span>Name
<span class="w"> </span>GPU<span class="w"> </span>activities:<span class="w">  </span><span class="m">100</span>.00%<span class="w">  </span><span class="m">2</span>.9741ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">2</span>.9741ms<span class="w">  </span><span class="m">2</span>.9741ms<span class="w">  </span><span class="m">2</span>.9741ms<span class="w">  </span>add<span class="o">(</span>int,<span class="w"> </span>float*,<span class="w"> </span>float*<span class="o">)</span>
<span class="w">      </span>API<span class="w"> </span>calls:<span class="w">   </span><span class="m">98</span>.47%<span class="w">  </span><span class="m">250</span>.63ms<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">125</span>.31ms<span class="w">  </span><span class="m">38</span>.785us<span class="w">  </span><span class="m">250</span>.59ms<span class="w">  </span>cudaMallocManaged
<span class="w">                    </span><span class="m">1</span>.18%<span class="w">  </span><span class="m">2</span>.9959ms<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">2</span>.9959ms<span class="w">  </span><span class="m">2</span>.9959ms<span class="w">  </span><span class="m">2</span>.9959ms<span class="w">  </span>cudaDeviceSynchronize
<span class="w">                    </span><span class="m">0</span>.24%<span class="w">  </span><span class="m">613</span>.16us<span class="w">         </span><span class="m">2</span><span class="w">  </span><span class="m">306</span>.58us<span class="w">  </span><span class="m">302</span>.27us<span class="w">  </span><span class="m">310</span>.89us<span class="w">  </span>cudaFree
<span class="w">                    </span><span class="m">0</span>.07%<span class="w">  </span><span class="m">188</span>.26us<span class="w">       </span><span class="m">101</span><span class="w">  </span><span class="m">1</span>.8630us<span class="w">     </span>169ns<span class="w">  </span><span class="m">86</span>.068us<span class="w">  </span>cuDeviceGetAttribute
<span class="w">                    </span><span class="m">0</span>.02%<span class="w">  </span><span class="m">38</span>.874us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">38</span>.874us<span class="w">  </span><span class="m">38</span>.874us<span class="w">  </span><span class="m">38</span>.874us<span class="w">  </span>cuDeviceGetName
<span class="w">                    </span><span class="m">0</span>.01%<span class="w">  </span><span class="m">37</span>.051us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">37</span>.051us<span class="w">  </span><span class="m">37</span>.051us<span class="w">  </span><span class="m">37</span>.051us<span class="w">  </span>cudaLaunchKernel
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">5</span>.7050us<span class="w">         </span><span class="m">1</span><span class="w">  </span><span class="m">5</span>.7050us<span class="w">  </span><span class="m">5</span>.7050us<span class="w">  </span><span class="m">5</span>.7050us<span class="w">  </span>cuDeviceGetPCIBusId
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">2</span>.2980us<span class="w">         </span><span class="m">3</span><span class="w">     </span>766ns<span class="w">     </span>224ns<span class="w">  </span><span class="m">1</span>.8050us<span class="w">  </span>cuDeviceGetCount
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>979ns<span class="w">         </span><span class="m">2</span><span class="w">     </span>489ns<span class="w">     </span>195ns<span class="w">     </span>784ns<span class="w">  </span>cuDeviceGet
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>587ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>587ns<span class="w">     </span>587ns<span class="w">     </span>587ns<span class="w">  </span>cuDeviceTotalMem
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>367ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>367ns<span class="w">     </span>367ns<span class="w">     </span>367ns<span class="w">  </span>cuModuleGetLoadingMode
<span class="w">                    </span><span class="m">0</span>.00%<span class="w">     </span>324ns<span class="w">         </span><span class="m">1</span><span class="w">     </span>324ns<span class="w">     </span>324ns<span class="w">     </span>324ns<span class="w">  </span><span class="nv">cuDeviceGetUuid</span>

<span class="o">==</span><span class="nv">8972</span><span class="o">==</span><span class="w"> </span>Unified<span class="w"> </span>Memory<span class="w"> </span>profiling<span class="w"> </span>result:
Device<span class="w"> </span><span class="s2">&quot;Tesla T4 (0)&quot;</span>
<span class="w">   </span>Count<span class="w">  </span>Avg<span class="w"> </span>Size<span class="w">  </span>Min<span class="w"> </span>Size<span class="w">  </span>Max<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Size<span class="w">  </span>Total<span class="w"> </span>Time<span class="w">  </span>Name
<span class="w">     </span><span class="m">106</span><span class="w">  </span><span class="m">77</span>.282KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">980</span>.00KB<span class="w">  </span><span class="m">8</span>.000000MB<span class="w">  </span><span class="m">969</span>.6510us<span class="w">  </span>Host<span class="w"> </span>To<span class="w"> </span>Device
<span class="w">      </span><span class="m">24</span><span class="w">  </span><span class="m">170</span>.67KB<span class="w">  </span><span class="m">4</span>.0000KB<span class="w">  </span><span class="m">0</span>.9961MB<span class="w">  </span><span class="m">4</span>.000000MB<span class="w">  </span><span class="m">363</span>.6760us<span class="w">  </span>Device<span class="w"> </span>To<span class="w"> </span>Host
<span class="w">      </span><span class="m">11</span><span class="w">         </span>-<span class="w">         </span>-<span class="w">         </span>-<span class="w">           </span>-<span class="w">  </span><span class="m">2</span>.908132ms<span class="w">  </span>Gpu<span class="w"> </span>page<span class="w"> </span>fault<span class="w"> </span>groups
Total<span class="w"> </span>CPU<span class="w"> </span>Page<span class="w"> </span>faults:<span class="w"> </span><span class="m">36</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
</section>
<section id="todo-openmp-offload-to-gpu">
<h3><span class="section-number">12.9.3. </span><span class="todo TODO">TODO</span> Openmp offload to gpu<a class="headerlink" href="#todo-openmp-offload-to-gpu" title="Link to this heading">#</a></h3>
<p>REF:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=uVcvecgdW7g">https://www.youtube.com/watch?v=uVcvecgdW7g</a></p></li>
</ul>
<p>Code</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;omp.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="mi">100</span><span class="p">],</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="mi">100</span><span class="p">],</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="mi">100</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Initialize arrays a and b</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">        </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_devices</span><span class="p">();</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Number of available devices %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">num_devices</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Offload computation to GPU</span>
<span class="w">    </span><span class="cp">#pragma omp target teams distribute parallel for map(to:a[0:100], b[0:100]) map(from:c[0:100])</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Print results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Does not work in sala2 due to the error</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>OpenMP<span class="w"> </span>GPU<span class="w"> </span>Offload<span class="w"> </span>is<span class="w"> </span>available<span class="w"> </span>only<span class="w"> </span>on<span class="w"> </span>systems<span class="w"> </span>with<span class="w"> </span>NVIDIA<span class="w"> </span>GPUs<span class="w"> </span>with<span class="w"> </span>compute<span class="w"> </span>capability<span class="w"> </span><span class="err">&#39;</span>&gt;<span class="o">=</span><span class="w"> </span>cc70
</pre></div>
</div>
<p>It seems that sala2 compute capability is 6.1. It can be get with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvidia-smi<span class="w"> </span>--query-gpu<span class="o">=</span>compute_cap<span class="w"> </span>--format<span class="o">=</span>csv
</pre></div>
</div>
<p>Using google collab I can compile it</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!nvcc<span class="w"> </span>-arch<span class="w"> </span>sm_75<span class="w"> </span>-O3<span class="w"> </span>-o<span class="w"> </span>openmp_offload<span class="w"> </span>openmp_offload.cpp<span class="w"> </span>-lgomp
</pre></div>
</div>
<p>and get</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Number<span class="w"> </span>of<span class="w"> </span>available<span class="w"> </span>devices<span class="w"> </span><span class="m">1</span>
<span class="m">0</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="m">6</span><span class="w"> </span><span class="m">9</span><span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">21</span><span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">33</span><span class="w"> </span><span class="m">36</span><span class="w"> </span>...
</pre></div>
</div>
<p>Check:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://enccs.github.io/openmp-gpu/target/">https://enccs.github.io/openmp-gpu/target/</a></p></li>
</ul>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Copyright (c) 2019 CSC Training */</span>
<span class="cm">/* Copyright (c) 2021 ENCCS */</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="cp">#ifdef _OPENMP</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;omp.h&gt;</span>
<span class="cp">#endif</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">num_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_devices</span><span class="p">();</span>
<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Number of available devices %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">num_devices</span><span class="p">);</span>

<span class="w">  </span><span class="cp">#pragma omp target</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">omp_is_initial_device</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Running on host</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">      </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">nteams</span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_teams</span><span class="p">();</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">nthreads</span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_num_threads</span><span class="p">();</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Running on device with %d teams in total and %d threads in each team</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="n">nteams</span><span class="p">,</span><span class="n">nthreads</span><span class="p">);</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

</pre></div>
</div>
</section>
<section id="todo-openacc-intro">
<h3><span class="section-number">12.9.4. </span><span class="todo TODO">TODO</span> OpenACC intro<a class="headerlink" href="#todo-openacc-intro" title="Link to this heading">#</a></h3>
<p>REF:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.openacc.org/">https://www.openacc.org/</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/OpenACC-CUDA-beginners/1.02_openacc-introduction/">https://enccs.github.io/OpenACC-CUDA-beginners/1.02_openacc-introduction/</a></p></li>
<li><p><a class="reference external" href="https://ulhpc-tutorials.readthedocs.io/en/latest/gpu/openacc/basics/">https://ulhpc-tutorials.readthedocs.io/en/latest/gpu/openacc/basics/</a></p></li>
</ul>
<p>Check if we are using the gpu or the cpu:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;openacc.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">device_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc_get_device_type</span><span class="p">();</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">device_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">acc_device_nvidia</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Running on an NVIDIA GPU</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">device_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">acc_device_radeon</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Running on an AMD GPU</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="c1">//} else if (device_type == acc_device_intel_mic) {</span>
<span class="w">    </span><span class="c1">//printf(&quot;Running on an Intel MIC\n&quot;);</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">device_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">acc_device_host</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Running on the host CPU</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Unknown device type</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile as</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>gcc<span class="w"> </span>-fopenacc<span class="w"> </span>mycode.c
</pre></div>
</div>
<p>Simple example:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="mi">100</span><span class="p">],</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="mi">100</span><span class="p">],</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="mi">100</span><span class="p">];</span>

<span class="w">  </span><span class="c1">// Initialize arrays</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Compute element-wise sum</span>
<span class="w">  </span><span class="cp">#pragma acc parallel loop</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Print result</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;%f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./12-IntroHPC"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../11-matrix-performance/11-matrix-performance.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Performance measurement for some matrix ops</p>
      </div>
    </a>
    <a class="right-next"
       href="../13-OpenMP/OpenMP-Intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">13. </span>Introduction to OpenMp (Shared memory)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">12.1. Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-parallel-metrics">12.2. Basics of parallel metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-overview-of-a-cluster-resources-and-use">12.3. Practical overview of a cluster resources and use</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openmp-shared-memory">12.4. Openmp, shared memory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">12.4.1. Exercises</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mpi-distributed-memory">12.5. MPI, distributed memory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-parallelization-farm-task-and-gnu-parallel-or-xargs">12.6. Simple parallelization: farm task and gnu parallel or xargs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-gnu-parallel-to-run-several-matmul-and-compute-metrics">12.6.1. Using gnu parallel to run several matmul and compute metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#threads-from-c-11">12.7. Threads from c++11</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">12.7.1. Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-algorithms-in-c">12.8. Parallel algorithms in c++</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-gpu-programming-intro">12.9. <span class="todo TODO">TODO</span> Gpu Programming intro</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup-for-cuda">12.9.1. Environment setup for cuda</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-cuda-intro">12.9.2. <span class="todo TODO">TODO</span> Cuda intro</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-openmp-offload-to-gpu">12.9.3. <span class="todo TODO">TODO</span> Openmp offload to gpu</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-openacc-intro">12.9.4. <span class="todo TODO">TODO</span> OpenACC intro</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By William Oquendo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>